<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="es" xml:lang="es"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.269">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Gabriel Fuentes">

<title>Gabriel Fuentes - Revelando los sentimientos guatemaltecos</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../favicon.png" rel="icon" type="image/png">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "Sin resultados",
    "search-matching-documents-text": "documentos encontrados",
    "search-copy-link-title": "Copiar el enlace en la búsqueda",
    "search-hide-matches-text": "Ocultar resultados adicionales",
    "search-more-match-text": "resultado adicional en este documento",
    "search-more-matches-text": "resultados adicionales en este documento",
    "search-clear-button-title": "Borrar",
    "search-detached-cancel-button-title": "Cancelar",
    "search-submit-button-title": "Enviar"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-SLRQS7H2TD"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-SLRQS7H2TD', { 'anonymize_ip': true});
</script>
<style>html{ scroll-behavior: smooth; }</style>
<style>
    .quarto-title-block .quarto-title-banner {
      background: #7EA1C2;
    }
    </style>

<script src="../../site_libs/kePrint-0.0.1/kePrint.js"></script>
<link href="../../site_libs/lightable-0.0.1/lightable.css" rel="stylesheet">


<link rel="stylesheet" href="../../styles.css">
<meta property="og:title" content="Gabriel Fuentes - Revelando los sentimientos guatemaltecos">
<meta property="og:description" content="Extracción zero-shot de variables para tweets acerca de las elecciones presidenciales 2023 usando GPT-3.5">
<meta property="og:image" content="https://gafnts.github.io/posts/election-insights/feature.png">
<meta property="og:site-name" content="Gabriel Fuentes">
<meta property="og:image:height" content="1450">
<meta property="og:image:width" content="1920">
<meta name="twitter:title" content="Gabriel Fuentes - Revelando los sentimientos guatemaltecos">
<meta name="twitter:description" content="Extracción zero-shot de variables para tweets acerca de las elecciones presidenciales 2023 usando GPT-3.5">
<meta name="twitter:image" content="https://gafnts.github.io/posts/election-insights/feature.png">
<meta name="twitter:image-height" content="1450">
<meta name="twitter:image-width" content="1920">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="floating nav-fixed slimcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a href="../../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../../favicon.png" alt="" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Gabriel Fuentes</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../index.html">
 <span class="menu-text">Blog</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../about.html">
 <span class="menu-text">Sobre mí</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/gafnts"><i class="bi bi-twitter" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/gafnts"><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default toc-left page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Revelando los sentimientos guatemaltecos</h1>
            <p class="subtitle lead">Extracción zero-shot de variables para tweets acerca de las elecciones presidenciales 2023 usando GPT-3.5</p>
                                <div class="quarto-categories">
                <div class="quarto-category">Natural language processing</div>
                <div class="quarto-category">Object-oriented programming</div>
                <div class="quarto-category">Data engineering</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Autor/a</div>
      <div class="quarto-title-meta-contents">
               <p>Gabriel Fuentes </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Fecha de publicación</div>
      <div class="quarto-title-meta-contents">
        <p class="date">12 de junio de 2023</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto">
    <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">En esta página</h2>
   
  <ul>
  <li><a href="#decodificando-sentimientos" id="toc-decodificando-sentimientos" class="nav-link active" data-scroll-target="#decodificando-sentimientos"><span class="toc-section-number">1</span>  Decodificando sentimientos</a></li>
  <li><a href="#extracción-de-tweets-con-tweepy" id="toc-extracción-de-tweets-con-tweepy" class="nav-link" data-scroll-target="#extracción-de-tweets-con-tweepy"><span class="toc-section-number">2</span>  Extracción de <em>tweets</em> con <em>Tweepy</em></a>
  <ul class="collapse">
  <li><a href="#enviando-requests-hacia-la-api" id="toc-enviando-requests-hacia-la-api" class="nav-link" data-scroll-target="#enviando-requests-hacia-la-api">Enviando <em>requests</em> hacia la API</a></li>
  <li><a href="#descargando-tweets-en-batches" id="toc-descargando-tweets-en-batches" class="nav-link" data-scroll-target="#descargando-tweets-en-batches">Descargando <em>tweets</em> en <em>batches</em></a></li>
  </ul></li>
  <li><a href="#zero-shot-feature-extraccion-con-gpt-3.5" id="toc-zero-shot-feature-extraccion-con-gpt-3.5" class="nav-link" data-scroll-target="#zero-shot-feature-extraccion-con-gpt-3.5"><span class="toc-section-number">3</span>  <em>Zero-shot feature extraccion</em> con GPT-3.5</a>
  <ul class="collapse">
  <li><a href="#enviando-requests-hacia-la-api-1" id="toc-enviando-requests-hacia-la-api-1" class="nav-link" data-scroll-target="#enviando-requests-hacia-la-api-1">Enviando <em>requests</em> hacia la API</a></li>
  <li><a href="#prompt-engineering" id="toc-prompt-engineering" class="nav-link" data-scroll-target="#prompt-engineering"><em>Prompt engineering</em></a></li>
  <li><a href="#zero-shot-feature-extraction" id="toc-zero-shot-feature-extraction" class="nav-link" data-scroll-target="#zero-shot-feature-extraction"><em>Zero-shot feature extraction</em></a></li>
  </ul></li>
  <li><a href="#análisis-de-la-opinión-pública" id="toc-análisis-de-la-opinión-pública" class="nav-link" data-scroll-target="#análisis-de-la-opinión-pública"><span class="toc-section-number">4</span>  Análisis de la opinión pública</a>
  <ul class="collapse">
  <li><a href="#explorando-el-dataset" id="toc-explorando-el-dataset" class="nav-link" data-scroll-target="#explorando-el-dataset">Explorando el <em>dataset</em></a></li>
  <li><a href="#analizando-sentimientos" id="toc-analizando-sentimientos" class="nav-link" data-scroll-target="#analizando-sentimientos">Analizando sentimientos</a></li>
  </ul></li>
  <li><a href="#conclusiones" id="toc-conclusiones" class="nav-link" data-scroll-target="#conclusiones"><span class="toc-section-number">5</span>  Conclusiones</a></li>
  </ul>
<div class="toc-actions"><div><i class="bi bi-github"></i></div><div class="action-links"><p><a href="https://github.com/gafnts/gafnts.github.io/edit/blog/posts/election-insights/index.qmd" class="toc-action">Editar esta página</a></p></div></div></nav>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
    </div>
<!-- main -->
<main class="content quarto-banner-title-block page-columns page-full" id="quarto-document-content">




<section id="decodificando-sentimientos" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="decodificando-sentimientos"><span class="header-section-number">1</span> Decodificando sentimientos</h2>
<p>Con las elecciones presidenciales a poco más de dos semanas de distancia, la importancia de comprender la voz del público no puede subestimarse. A través del uso de técnicas avanzadas, esta entrada busca no solo descubrir patrones en el sentimiento público, sino también demostrar cómo la nueva generación de modelos de lenguaje pueden emplearse para ofrecer perspectivas únicas y valiosas en la dinámica social y política de los países. Específicamente, utilizaremos dos poderosos recursos para llevar a cabo este análisis: la API de <em>Twitter</em> y la API de <em>OpenAI</em>.</p>
<ul>
<li>Primero, descargaremos tweets que mencionan a los cinco candidatos que lideraban la encuesta de Prensa Libre publicada a principios de mayo desde la <em>Twitter API V2</em> utilizando <em>Python.</em></li>
<li>Estos tweets, entonces, servirán como nuestro conjunto de datos base para extraer características utilizando la API de <em>OpenAI</em> y su modelo de lenguaje <code>gpt-3.5-turbo</code>, empleando una técnica llamada <em>zero-shot feature extraction</em>.</li>
<li>Por último, realizaremos una breve exploración de los resultados utilizando <em>R</em>, mi herramienta favorita cuando se trata de procedimientos estadísticos y de análisis de datos.</li>
</ul>
<p>A lo largo del blog, explicaremos cómo funcionan estas APIs, cómo utilizarlas implementando clases en <em>Python</em> lo suficientemente robustas como para lidiar con sus errores y excepciones, y cómo estos resultados se pueden utilizar para realizar un análisis profundo y significativo.</p>
<p>Desde hace varios años, la intersección entre las ciencias de la computación y las ciencias sociales se ha transformado en uno de mis temas favoritos. Es verdaderamente emocionante darse cuenta de que nos encontramos en un momento único, en el cual es posible emplear tecnologías de vanguardia para obtener <em>insights</em> de eventos significativos. Quizás es más emocionante aún considerar que este tipo de análisis habría sido prácticamente imposible de llevar a cabo hace solo dos años. ¿Lista? ¿Listo?</p>
</section>
<section id="extracción-de-tweets-con-tweepy" class="level2 page-columns page-full" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="extracción-de-tweets-con-tweepy"><span class="header-section-number">2</span> Extracción de <em>tweets</em> con <em>Tweepy</em></h2>
<div class="page-columns page-full"><p>Okay. Cartas sobre la mesa. Implementar estos programas ha conllevado bastante de mi tiempo libre en las últimas semanas; estoy seguro de que leer todos los detalles sobre estas implementaciones también requeriría de una cantidad de tiempo considerable, por lo que en esta y la siguiente sección únicamente haremos un repaso por los puntos más importantes<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>.</p><div class="no-row-height column-margin column-container"><li id="fn1"><p><sup>1</sup>&nbsp;Para los lectores más interesados he publicado <a href="https://github.com/gafnts/2023-election-insights">este repositorio</a> en el es posible encontrar todos los programas y módulos utilizados para generar estos resultados. Las clases y sus métodos fueron debidamente documentados, pero siéntete libre de contactarme si te gustaría saber más sobre los detalles de estas implementaciones.</p></li></div></div>
<section id="enviando-requests-hacia-la-api" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="enviando-requests-hacia-la-api">Enviando <em>requests</em> hacia la API</h3>
<p>La estructura del repositorio es extremadamente sencilla y el diseño de las clases se adhiere al <em>single-responsibility principle</em>. El directorio <code>modules</code> contiene las clases encargadas de comunicarse con las APIs, mientras que los programas <code>download_tweets.py</code> y <code>extract_features.py</code> se encargan de descargar la información en <em>batches</em>. En el caso del procedimiento de extracción de <em>tweets</em>, el módulo <code>twitter_request.py</code> contiene a la clase <code>TwitterRequest</code>, responsable de comunicarse con la <em>Twitter API V2</em> siguiendo los siguientes pasos:</p>
<ul>
<li>Consultar el <em>endpoint</em> <code>GET_2_tweets_search_recent</code> de la API utilizando al método <code>search_recent_tweets</code> para extraer los <em>tweets</em> que necesitamos.</li>
<li>Procesar la respuesta de la API en formato JSON, conviertiéndola primero en un <em>DataFrame</em>.</li>
<li>Separar a ese <em>DataFrame</em> en dos: Uno que contenga información de los <em>tweets</em> y otro que contenga información de los usuarios que realizaron dichas publicaciones.</li>
<li>Preprocesar ambos <em>DataFrames</em> para estandarizar los nombres de las columnas y cambiar las columnas que contienen fechas a un formato más conveniente.</li>
</ul>
<p>En esta clase, el método más importante es <code>make_request</code>. Este método está decorado con <code>@backoff.on_exception</code> una forma increíblemente conveniente de hacer <a href="https://en.wikipedia.org/wiki/Exponential_backoff"><em>exponential backoff</em></a> en el momento en el que se produzca un error por generar demasiados <em>requests</em> o una excepción producto de un <em>timeout</em> entre nuestro cliente y el servidor. En cualquiera de estos casos, la función esperará un tiempo exponencialmente creciente antes de volver a intentarlo y únicamente hará un máximo de 5 intentos.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1"></a><span class="im">import</span> tweepy</span>
<span id="cb1-2"><a href="#cb1-2"></a><span class="im">import</span> backoff</span>
<span id="cb1-3"><a href="#cb1-3"></a><span class="im">import</span> requests</span>
<span id="cb1-4"><a href="#cb1-4"></a><span class="im">from</span> modules <span class="im">import</span> setup_logger</span>
<span id="cb1-5"><a href="#cb1-5"></a></span>
<span id="cb1-6"><a href="#cb1-6"></a><span class="at">@backoff.on_exception</span>(</span>
<span id="cb1-7"><a href="#cb1-7"></a>        backoff.expo, </span>
<span id="cb1-8"><a href="#cb1-8"></a>        (tweepy.errors.TooManyRequests, requests.exceptions.ReadTimeout),</span>
<span id="cb1-9"><a href="#cb1-9"></a>        max_tries<span class="op">=</span><span class="dv">5</span></span>
<span id="cb1-10"><a href="#cb1-10"></a>    )</span>
<span id="cb1-11"><a href="#cb1-11"></a><span class="kw">def</span> make_request(<span class="va">self</span>) <span class="op">-&gt;</span> <span class="st">"TwitterRequest"</span>:</span>
<span id="cb1-12"><a href="#cb1-12"></a>    <span class="va">self</span>.query <span class="op">=</span> <span class="ss">f"</span><span class="sc">{</span><span class="va">self</span><span class="sc">.</span>query<span class="sc">}</span><span class="ss"> -is:retweet -is:reply"</span></span>
<span id="cb1-13"><a href="#cb1-13"></a>    <span class="va">self</span>.logger.info(<span class="st">"Making request with query: </span><span class="sc">%s</span><span class="st">"</span>, <span class="va">self</span>.query)</span>
<span id="cb1-14"><a href="#cb1-14"></a></span>
<span id="cb1-15"><a href="#cb1-15"></a>    <span class="cf">try</span>:</span>
<span id="cb1-16"><a href="#cb1-16"></a>        <span class="va">self</span>.tweets <span class="op">=</span> client.search_recent_tweets(</span>
<span id="cb1-17"><a href="#cb1-17"></a>            query <span class="op">=</span> <span class="va">self</span>.query,</span>
<span id="cb1-18"><a href="#cb1-18"></a>            start_time <span class="op">=</span> <span class="va">self</span>.start_time,</span>
<span id="cb1-19"><a href="#cb1-19"></a>            end_time <span class="op">=</span> <span class="va">self</span>.end_time,</span>
<span id="cb1-20"><a href="#cb1-20"></a>            max_results <span class="op">=</span> <span class="va">self</span>.max_results,</span>
<span id="cb1-21"><a href="#cb1-21"></a>            tweet_fields <span class="op">=</span> [</span>
<span id="cb1-22"><a href="#cb1-22"></a>                <span class="st">"id"</span>, <span class="st">"author_id"</span>, <span class="st">"created_at"</span>, <span class="st">"text"</span>, </span>
<span id="cb1-23"><a href="#cb1-23"></a>                <span class="st">"public_metrics"</span>, <span class="st">"possibly_sensitive"</span>, <span class="st">"lang"</span></span>
<span id="cb1-24"><a href="#cb1-24"></a>            ],</span>
<span id="cb1-25"><a href="#cb1-25"></a>            user_fields <span class="op">=</span> [</span>
<span id="cb1-26"><a href="#cb1-26"></a>                <span class="st">"id"</span>, <span class="st">"username"</span>, <span class="st">"name"</span>, <span class="st">"location"</span>, <span class="st">"created_at"</span>, <span class="st">"description"</span>, </span>
<span id="cb1-27"><a href="#cb1-27"></a>                <span class="st">"profile_image_url"</span>, <span class="st">"verified"</span>, <span class="st">"public_metrics"</span></span>
<span id="cb1-28"><a href="#cb1-28"></a>            ],</span>
<span id="cb1-29"><a href="#cb1-29"></a>            expansions <span class="op">=</span> [</span>
<span id="cb1-30"><a href="#cb1-30"></a>                <span class="st">"author_id"</span>, <span class="st">"referenced_tweets.id"</span></span>
<span id="cb1-31"><a href="#cb1-31"></a>            ]</span>
<span id="cb1-32"><a href="#cb1-32"></a>        )</span>
<span id="cb1-33"><a href="#cb1-33"></a>        </span>
<span id="cb1-34"><a href="#cb1-34"></a>        <span class="cf">if</span> <span class="va">self</span>.tweets <span class="kw">is</span> <span class="va">None</span> <span class="kw">or</span> <span class="va">self</span>.tweets.data <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb1-35"><a href="#cb1-35"></a>            <span class="va">self</span>.logger.error(<span class="st">"No tweets returned from request"</span>)</span>
<span id="cb1-36"><a href="#cb1-36"></a>            <span class="cf">return</span> <span class="va">self</span></span>
<span id="cb1-37"><a href="#cb1-37"></a>          </span>
<span id="cb1-38"><a href="#cb1-38"></a>    <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e: </span>
<span id="cb1-39"><a href="#cb1-39"></a>        <span class="va">self</span>.logger.error(<span class="st">"Exception occurred"</span>, exc_info<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb1-40"><a href="#cb1-40"></a>        <span class="cf">raise</span> </span>
<span id="cb1-41"><a href="#cb1-41"></a></span>
<span id="cb1-42"><a href="#cb1-42"></a>    <span class="va">self</span>.logger.info(<span class="st">"Request completed successfully."</span>)</span>
<span id="cb1-43"><a href="#cb1-43"></a>    <span class="cf">return</span> <span class="va">self</span></span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="page-columns page-full"><p>El mismo método define el <em>query</em> que se llevará a cabo, que en nuestro caso es un <em>string</em> con el nombre del candidato mencionado en los <em>tweets</em>, pero instruimos a la API para que no devuelva <em>tweets</em> que sean <em>retweets</em> o respuestas (<code>f"{self.query} -is:retweet -is:reply"</code>). En la solicitud, se incluyen campos específicos de los tweets y del usuario que los publicó. Por ejemplo, del <em>tweet</em> se solicita el ID, el autor, la fecha de creación, el texto, las métricas como cantidad de <em>retweets</em>, <em>likes</em> o respuestas, así como si la publicación tienen contenido sensible y cuál es su idioma. Del usuario solicitamos el ID, el nombre de usuario, el nombre, la ubicación, la fecha de creación del perfil, la descripción, la imagen de perfil, sus métricas públicas y si su perfil está verificado o no<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>.</p><div class="no-row-height column-margin column-container"><li id="fn2"><p><sup>2</sup>&nbsp;Aunque mis procedimientos extrajeron toda esta información para más de 5,000 tweets que fueron publicados por múltiples usuarios durante las últimas dos semanas, el <em>Developer Agreement and Policy</em> de <em>Twitter</em> me prohibe publicar la totalidad de la información. Sin embargo, he publicado un <a href="https://github.com/gafnts/2023-election-insights/blob/main/data/tweets_gpt.csv">dataset reducido</a> que contiene 1,420 tweets con sus respectivas métricas públicas y las características extraídas utilizando al modelo de lenguaje.</p></li></div></div>
<p>Si la solicitud es exitosa, se obtiene cierta cantidad de <em>tweets</em> que son almacenados en el atributo <code>self.tweets</code>. Si no se obtiene ningún <em>tweet</em>, se registra un error en el <em>log</em>. Si ocurre alguna otra excepción durante la solicitud, también se registra en el <em>log</em> y es levantada para que pueda ser manejada por el decorador encargado de hacer exponential <em>backoff</em>. Por último, si la solicitud se completó con éxito, registramos este hecho en el <em>log</em> y retornamos al objeto <code>self</code>, para darnos la posibilidad de hacer <a href="https://stackoverflow.com/questions/41817578/basic-method-chaining"><em>method chaining</em></a>.</p>
<p>De esta forma, utilizar la clase <code>TwitterRequest</code> requiere únicamente de inicializarla con los parámetros <code>query</code>, <code>start_time</code>, <code>end_time</code> y <code>max_results</code>. <em>Like so</em>:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1"></a><span class="im">from</span> datetime <span class="im">import</span> datetime</span>
<span id="cb2-2"><a href="#cb2-2"></a><span class="im">from</span> modules <span class="im">import</span> TwitterRequest</span>
<span id="cb2-3"><a href="#cb2-3"></a></span>
<span id="cb2-4"><a href="#cb2-4"></a>tweets, users <span class="op">=</span> (</span>
<span id="cb2-5"><a href="#cb2-5"></a>  TwitterRequest(</span>
<span id="cb2-6"><a href="#cb2-6"></a>      query<span class="op">=</span><span class="st">'zury rios'</span>,</span>
<span id="cb2-7"><a href="#cb2-7"></a>      start_time<span class="op">=</span>datetime(<span class="dv">2023</span>, <span class="dv">5</span>, <span class="dv">20</span>, <span class="dv">15</span>, <span class="dv">00</span>),</span>
<span id="cb2-8"><a href="#cb2-8"></a>      end_time<span class="op">=</span>datetime(<span class="dv">2023</span>, <span class="dv">5</span>, <span class="dv">21</span>, <span class="dv">15</span>, <span class="dv">00</span>),</span>
<span id="cb2-9"><a href="#cb2-9"></a>      max_results<span class="op">=</span><span class="dv">10</span></span>
<span id="cb2-10"><a href="#cb2-10"></a>  )</span>
<span id="cb2-11"><a href="#cb2-11"></a>  .make_request()</span>
<span id="cb2-12"><a href="#cb2-12"></a>  .tweets_to_dataframe()</span>
<span id="cb2-13"><a href="#cb2-13"></a>  .users_to_dataframe()</span>
<span id="cb2-14"><a href="#cb2-14"></a>  .segregate_dataframe()</span>
<span id="cb2-15"><a href="#cb2-15"></a>  .preprocess_data(</span>
<span id="cb2-16"><a href="#cb2-16"></a>      tweets_prefix<span class="op">=</span><span class="st">'tw_'</span>,</span>
<span id="cb2-17"><a href="#cb2-17"></a>      users_prefix<span class="op">=</span><span class="st">'us_'</span></span>
<span id="cb2-18"><a href="#cb2-18"></a>  )</span>
<span id="cb2-19"><a href="#cb2-19"></a>)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="descargando-tweets-en-batches" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="descargando-tweets-en-batches">Descargando <em>tweets</em> en <em>batches</em></h3>
<div class="page-columns page-full"><p>Tenemos una forma de comunicarnos con la API de <em>Twitter</em>, pedirle los datos que nos interesan y preprocesarlos para que estén listos para el resto del <em>pipeline</em>. Sin embargo, <em>Twitter</em> no nos va a hacer la vida fácil. Su API únicamente permite descargar <em>tweets</em> publicados en los últimos 7 días en batches de 60 <em>tweets</em> como máximo en un espacio de 15 minutos.<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a></p><div class="no-row-height column-margin column-container"><li id="fn3"><p><sup>3</sup>&nbsp;<em>Overprotective much?</em></p></li></div></div>
<p>Ni modo. El programa <code>download_tweets.py</code> esta diseñado para lidiar con las restricciones de la API de <em>Twitter</em>. El método <code>download_tweets</code> es un componente de la clase <code>DownloadTweets.</code> En resumen, este método descarga <em>tweets</em> y usuarios (utilizando el método <code>get_batch</code>, que es un <em>wrapper</em> para la clase <code>TwitterRequest</code>). Para cada candidato y rango de fechas, se invoca el método <code>get_batch</code> para obtener los <em>tweets</em> y usuarios, que se recopilan y se concatenan en dos atributos: <code>self.tweets</code> y <code>self.users</code>. Finalmente, el método devuelve estos dos <em>DataFrames</em> que contienen todos los <em>tweets</em> y usuarios recolectados.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb3-2"><a href="#cb3-2"></a><span class="im">from</span> typing <span class="im">import</span> Tuple</span>
<span id="cb3-3"><a href="#cb3-3"></a><span class="im">from</span> modules <span class="im">import</span> setup_logger</span>
<span id="cb3-4"><a href="#cb3-4"></a><span class="im">from</span> modules <span class="im">import</span> TwitterRequest</span>
<span id="cb3-5"><a href="#cb3-5"></a></span>
<span id="cb3-6"><a href="#cb3-6"></a><span class="kw">def</span> download_tweets(<span class="va">self</span>) <span class="op">-&gt;</span> Tuple[pd.DataFrame, pd.DataFrame]:</span>
<span id="cb3-7"><a href="#cb3-7"></a>    <span class="va">self</span>.generate_dates()</span>
<span id="cb3-8"><a href="#cb3-8"></a>    logger.info(<span class="ss">f"Generated </span><span class="sc">{</span><span class="bu">len</span>(<span class="va">self</span>.dates)<span class="sc">}</span><span class="ss"> date pairs for tweet downloads."</span>)</span>
<span id="cb3-9"><a href="#cb3-9"></a></span>
<span id="cb3-10"><a href="#cb3-10"></a>    <span class="co"># Collect tweets and users for each candidate.</span></span>
<span id="cb3-11"><a href="#cb3-11"></a>    tweets_collector, users_collector <span class="op">=</span> [], []</span>
<span id="cb3-12"><a href="#cb3-12"></a>    <span class="cf">for</span> candidate <span class="kw">in</span> <span class="va">self</span>.candidates:</span>
<span id="cb3-13"><a href="#cb3-13"></a></span>
<span id="cb3-14"><a href="#cb3-14"></a>        <span class="co"># Collect tweets and users for each date.</span></span>
<span id="cb3-15"><a href="#cb3-15"></a>        dates_tweets_collector, dates_users_collector <span class="op">=</span> [], []</span>
<span id="cb3-16"><a href="#cb3-16"></a>        <span class="cf">for</span> start_date, end_date <span class="kw">in</span> <span class="va">self</span>.dates:</span>
<span id="cb3-17"><a href="#cb3-17"></a></span>
<span id="cb3-18"><a href="#cb3-18"></a>            tweets, users <span class="op">=</span> <span class="va">self</span>.get_batch(candidate, start_date, end_date)</span>
<span id="cb3-19"><a href="#cb3-19"></a>            dates_tweets_collector.append(tweets)</span>
<span id="cb3-20"><a href="#cb3-20"></a>            dates_users_collector.append(users)</span>
<span id="cb3-21"><a href="#cb3-21"></a></span>
<span id="cb3-22"><a href="#cb3-22"></a>        tweets_collector.append(pd.concat(dates_tweets_collector))</span>
<span id="cb3-23"><a href="#cb3-23"></a>        users_collector.append(pd.concat(dates_users_collector))</span>
<span id="cb3-24"><a href="#cb3-24"></a></span>
<span id="cb3-25"><a href="#cb3-25"></a>    <span class="va">self</span>.tweets <span class="op">=</span> pd.concat(tweets_collector, axis<span class="op">=</span><span class="dv">0</span>, ignore_index<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb3-26"><a href="#cb3-26"></a>    <span class="va">self</span>.users <span class="op">=</span> pd.concat(users_collector, axis<span class="op">=</span><span class="dv">0</span>, ignore_index<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb3-27"><a href="#cb3-27"></a></span>
<span id="cb3-28"><a href="#cb3-28"></a>    logger.info(</span>
<span id="cb3-29"><a href="#cb3-29"></a>      <span class="ss">f"Downloaded a total of </span><span class="sc">{</span><span class="bu">len</span>(<span class="va">self</span>.tweets)<span class="sc">}</span><span class="ss"> tweets and </span><span class="sc">{</span><span class="bu">len</span>(<span class="va">self</span>.users)<span class="sc">}</span><span class="ss"> users."</span></span>
<span id="cb3-30"><a href="#cb3-30"></a>    )</span>
<span id="cb3-31"><a href="#cb3-31"></a>    <span class="cf">return</span> <span class="va">self</span>.tweets, <span class="va">self</span>.users</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
</section>
<section id="zero-shot-feature-extraccion-con-gpt-3.5" class="level2 page-columns page-full" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="zero-shot-feature-extraccion-con-gpt-3.5"><span class="header-section-number">3</span> <em>Zero-shot feature extraccion</em> con GPT-3.5</h2>
<p>Ahora viene una de mis partes favoritas en este proceso. Vamos a usar a GPT-3.5 para generar nuevas <em>features</em> basadas en los <em>tweets</em> que hemos extraído. ¿Cómo? <em>Much in the same way we downloaded tweets</em>, usando una clase llamada <code>OpenAIRequest</code> (que se encargará de comunicarse con la API) y otra, llamada <code>FeatureExtraction</code>, que nos servirá para iterar en las filas del <em>DataFrame</em> que contiene las publicaciones de los usuarios de <em>Twitter</em>.</p>
<section id="enviando-requests-hacia-la-api-1" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="enviando-requests-hacia-la-api-1">Enviando <em>requests</em> hacia la API</h3>
<p>El primer método relevante en la clase <code>OpenAIRequest</code> es <code>make_request</code>. De manera similar al método con el mismo nombre en el procedimiento de extracción de <em>tweets</em>, esta función estática está decorada con <code>backoff.on_exception</code> para poder lidiar con errores en el caso de un <em>timeout</em> o por sobrepasar los límites de uso de la API. En el caso del modelo <code>gpt-3.5-turbo</code>, podemos realizar una cantidad de 3,500 <em>requests</em> por minuto o enviar al <em>endpoint</em> un máximo 90,000 <em>tokens</em> en la misma cantidad de tiempo, lo que pase primero.</p>
<div class="page-columns page-full"><p>Como veremos más adelante, el <em>prompt</em> con el que instruiremos al modelo tiene, en promedio, 600 <em>tokens.</em><a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a> En teoría, esto quiere decir que (basándonos en el límite de TPM) podemos enviar 150 <em>requests</em> cada 60 segundos. En la práctica, <em>though</em>, los tiempos de inferencia de los modelos de lenguaje son bastante altos. En nuestro caso, el tiempo de procesamiento por cada <em>tweet</em> fue de aproximadamente 15 segundos, así que extraer características para 1,420 <em>tweets</em> fue un proceso que tomó 6 horas, <em>give or take</em>.</p><div class="no-row-height column-margin column-container"><li id="fn4"><p><sup>4</sup>&nbsp;<em>OpenAI</em> pone a nuestra disposición este <a href="https://platform.openai.com/tokenizer">tokenizer</a>, una herramienta que nos permite hacer un recuento de la cantidad de <em>tokens</em> en nuestros <em>prompts</em>. En lo personal, me sirve muchísimo para calcular los costos de procesamiento y para asegurarme de que mis <em>prompts</em> sean eficientes en términos de longitud.</p></li></div></div>
<div class="page-columns page-full"><p>Los parámetros que acepta <code>make_request</code> son nuestro <em>prompt</em>, la especificación del modelo que queremos utilizar y <code>temperature</code>, un parámetro del modelo de lenguaje que puede ser un número entre 0 y 1. La temperatura controla el grado de aleatoriedad en las respuestas del modelo. Un valor de <code>temperature</code> más alto (cerca de 1) hace que el modelo genere respuestas más diversas y creativas, mientras que un valor más bajo (cerca de 0) hace que las respuestas sean más determinísticas o consistentes.<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a></p><div class="no-row-height column-margin column-container"><li id="fn5"><p><sup>5</sup>&nbsp;Los <em>transformers</em>, como GPT, son en sí mismos arquitecturas de redes neuronales determinísticas (es decir, generan la misma salida para una entrada específica). Sin embargo, se introduce aleatoriedad durante la generación de texto a través del muestreo de diferentes secuencias de palabras de acuerdo a las probabilidades de salida del modelo. En general, cuando usamos al modelo como un paso de procesamiento dentro de nuestros <em>pipelines</em>, queremos que cada respuesta sea lo más consistente posible para reducir las posibilidades de introducir <em>bugs</em> en nuestro sistema.</p></li></div></div>
<div class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1"></a><span class="im">import</span> openai</span>
<span id="cb4-2"><a href="#cb4-2"></a><span class="im">import</span> backoff</span>
<span id="cb4-3"><a href="#cb4-3"></a><span class="im">import</span> requests</span>
<span id="cb4-4"><a href="#cb4-4"></a></span>
<span id="cb4-5"><a href="#cb4-5"></a><span class="at">@staticmethod</span></span>
<span id="cb4-6"><a href="#cb4-6"></a><span class="at">@backoff.on_exception</span>(</span>
<span id="cb4-7"><a href="#cb4-7"></a>    backoff.expo, </span>
<span id="cb4-8"><a href="#cb4-8"></a>    (openai.error.RateLimitError, requests.exceptions.ReadTimeout),</span>
<span id="cb4-9"><a href="#cb4-9"></a>    max_tries<span class="op">=</span><span class="dv">5</span></span>
<span id="cb4-10"><a href="#cb4-10"></a>)</span>
<span id="cb4-11"><a href="#cb4-11"></a><span class="kw">def</span> make_request(prompt: <span class="bu">str</span>, model: <span class="bu">str</span> <span class="op">=</span> <span class="st">"gpt-3.5-turbo"</span>, temperature: <span class="bu">float</span> <span class="op">=</span> <span class="dv">0</span>) <span class="op">-&gt;</span> <span class="bu">str</span>: </span>
<span id="cb4-12"><a href="#cb4-12"></a>    messages <span class="op">=</span> [{<span class="st">"role"</span>: <span class="st">"user"</span>, <span class="st">"content"</span>: prompt}]</span>
<span id="cb4-13"><a href="#cb4-13"></a>    response <span class="op">=</span> openai.ChatCompletion.create(</span>
<span id="cb4-14"><a href="#cb4-14"></a>        model<span class="op">=</span>model,</span>
<span id="cb4-15"><a href="#cb4-15"></a>        messages<span class="op">=</span>messages,</span>
<span id="cb4-16"><a href="#cb4-16"></a>        temperature<span class="op">=</span>temperature, </span>
<span id="cb4-17"><a href="#cb4-17"></a>    )</span>
<span id="cb4-18"><a href="#cb4-18"></a>    <span class="cf">return</span> response.choices[<span class="dv">0</span>].message[<span class="st">"content"</span>]</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>El siguiente método relevante en la clase <code>OpenAIRequest</code> es <code>extract_features</code>. En este método, definimos el <em>prompt</em> que será utilizado para instruir al modelo de lenguaje. Este <em>prompt</em> es parametrizado a través de una <em>f string</em>, para permitirnos cambiar fácilmente la entrada según sea necesario.</p>
<p>Una vez definido el <em>prompt</em>, realizamos la consulta a la API de <em>OpenAI</em> utilizando el método <code>make_request</code>. Si la respuesta obtenida es nula o inválida, registramos un error en el log y retornamos <code>None</code>. Además, para robustecer al procedimiento y manejar posibles excepciones durante la solicitud a la API, hemos envuelto este segmento de código dentro de un bloque <em>Try Except</em>. Si todo sale según lo planeado y obtenemos una respuesta válida, la misma es cargada como un diccionario JSON y finalmente retornada por el método <code>extract_features</code>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1"></a><span class="im">import</span> json</span>
<span id="cb5-2"><a href="#cb5-2"></a><span class="im">from</span> modules <span class="im">import</span> setup_logger</span>
<span id="cb5-3"><a href="#cb5-3"></a></span>
<span id="cb5-4"><a href="#cb5-4"></a><span class="kw">def</span> extract_features(<span class="va">self</span>, prefix: <span class="bu">str</span>) <span class="op">-&gt;</span> <span class="bu">dict</span>:</span>
<span id="cb5-5"><a href="#cb5-5"></a>    prompt <span class="op">=</span> <span class="ss">f""" (...) """</span></span>
<span id="cb5-6"><a href="#cb5-6"></a>    </span>
<span id="cb5-7"><a href="#cb5-7"></a>    <span class="cf">try</span>:</span>
<span id="cb5-8"><a href="#cb5-8"></a>        response <span class="op">=</span> OpenAIRequest.make_request(prompt)</span>
<span id="cb5-9"><a href="#cb5-9"></a>        <span class="cf">if</span> response <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb5-10"><a href="#cb5-10"></a>            <span class="va">self</span>.logger.error(<span class="st">"Received invalid response from OpenAI"</span>)</span>
<span id="cb5-11"><a href="#cb5-11"></a>            <span class="cf">return</span> <span class="va">None</span></span>
<span id="cb5-12"><a href="#cb5-12"></a>        response <span class="op">=</span> json.loads(response)</span>
<span id="cb5-13"><a href="#cb5-13"></a>    <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb5-14"><a href="#cb5-14"></a>        <span class="va">self</span>.logger.error(<span class="ss">f"Exception during API request: </span><span class="sc">{</span>e<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb5-15"><a href="#cb5-15"></a>        <span class="cf">return</span> <span class="va">None</span></span>
<span id="cb5-16"><a href="#cb5-16"></a></span>
<span id="cb5-17"><a href="#cb5-17"></a>    <span class="cf">return</span> response</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="prompt-engineering" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="prompt-engineering"><em>Prompt engineering</em></h3>
<div class="page-columns page-full"><p>Tengo que confesar algo. Hace unas semanas leí en una publicación de <em>LinkedIn</em> una frase que decía algo así como: “<em>Calling ‘prompt engineering’ the action of using ChatGPT today is like calling ‘search engineering’ to googling something in the early 2000s</em>”. Y la confesión es que… pienso que es verdad.<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a></p><div class="no-row-height column-margin column-container"><li id="fn6"><p><sup>6</sup>&nbsp;Por cierto, ya que estamos confesando cosas. La idea de esta entrada surgió porque hace poco más de un mes vi los videos del curso de <em>deeplearning.ai</em> llamado <a href="https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/"><em>ChatGPT Prompt Engineering for Developers</em></a>. Es un curso extremadamente corto que tiene información útil acerca de los casos de uso del modelo desde una perspectiva programática. Si estás leyendo este blog, <em>chances are you’re also gonna like this</em>.</p></li></div></div>
<p><em>Nontheless</em>, considero que cuando vamos un paso más allá y utilizamos estos modelos desde los <em>endpoints</em> que <em>OpenAI</em> pone a nuestra disposición, el <em>hype</em> que existe hacia el término está un poco más justificado. Principalmente porque, aunque redactamos la instrucción en lenguaje natural, el procedimiento recuerda mucho a definir una serie de pasos en cualquier lenguaje de programación.</p>
<p>Para nuestros fines, este <em>prompt</em> dio buenos resultados:</p>
<div class="column-page-right">
<div class="callout-tip callout callout-style-simple">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container">
<div class="cell">
<div class="sourceCode cell-code" id="cb6" data-code-line-numbers="false"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>prompt <span class="op">=</span> <span class="ss">f"""</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="ss">El siguiente es un tweet que menciona a un candidato presidencial dentro de la contienda electoral 2023 en Guatemala. </span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="ss">Por favor, clasifícalo de acuerdo a las siguientes categorías:</span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a><span class="ss">Valencia (sentimiento general): [positivo, negativo, neutro, otro]</span></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a><span class="ss">Emoción (emoción principal expresada): [felicidad, tristeza, enojo, miedo, sorpresa, disgusto, otro]</span></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a><span class="ss">Postura (actitud hacia el tema): [aprobación, desaprobación, esperanza, desilusión, indiferencia, confianza, desconfianza, otro]</span></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a><span class="ss">Tono (forma de expresarse): [agresivo, pasivo, asertivo, escéptico, irónico, humorístico, informativo, serio, inspirador, otro]</span></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a><span class="ss">Además, evalúalo utilizando una escala continua con rango de 0 a 1 en las siguientes dimensiones:</span></span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a><span class="ss">Amabilidad (nivel de cortesía): [0.0 - 1.0]</span></span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a><span class="ss">Legibilidad (facilidad de lectura): [0.0 - 1.0]</span></span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a><span class="ss">Controversialidad (potencial para generar desacuerdo): [0.0 - 1.0]</span></span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a><span class="ss">Informatividad (cantidad de información relevante y fundamentada): [0.0 - 1.0]</span></span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a><span class="ss">Formatea tu respuesta como un diccionario de Python con las siguientes llaves:</span></span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a><span class="ss">[valencia, emocion, postura, tono, amabilidad, legibilidad, controversialidad, informatividad]</span></span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a><span class="ss">Tweet: '''</span><span class="sc">{</span><span class="va">self</span><span class="sc">.</span>tweet<span class="sc">}</span><span class="ss">'''</span></span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a><span class="ss">"""</span></span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="zero-shot-feature-extraction" class="level3">
<h3 class="anchored" data-anchor-id="zero-shot-feature-extraction"><em>Zero-shot feature extraction</em></h3>
<p>Estamos muy cerca de obtener los resultados que buscamos. Hasta el momento, los módulos que hemos implementado nos permiten enviar consultas hacia las APIs de <em>Twitter</em> y <em>OpenAI</em>, así como descargar lotes de <em>tweets</em> que mencionan a los cinco candidatos que encabezaban la encuesta de Prensa Libre, publicada a inicios de mayo. Solo nos falta una forma procesar estos tweets para extraer variables que nos permitan analizarlos a una mayor profundidad. <em>Enter</em> <code>extract_features.py</code>, un programa en el que la clase <code>OpenAIRequest</code> es instanciada dentro de la clase <code>FeatureExtraction</code>.</p>
<p>En el constructor de la clase se inicializan las rutas a dos archivos: <code>df_path</code> que es la ruta al archivo CSV de entrada que contiene los <em>tweets</em>, y <code>results_df_path</code> que es la ruta al archivo csv de salida donde se almacenarán las variables extraídas.</p>
<p>El principal método de esta clase es <code>extract_features</code>. Este método primero carga los <em>tweets</em> del archivo CSV de entrada y elimina los duplicados. Luego intenta cargar las características ya extraídas del archivo CSV de salida. Si este archivo no existe, se inicializa un nuevo <em>DataFrame</em> vacío. El método luego determina qué <em>tweets</em> aún no han sido procesados comparando los <em>tweets</em> en los dos <em>DataFrames</em> y seleccionando aquellos que solo están en el <em>DataFrame</em> de entrada.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb7-2"><a href="#cb7-2"></a><span class="im">from</span> modules <span class="im">import</span> OpenAIRequest</span>
<span id="cb7-3"><a href="#cb7-3"></a></span>
<span id="cb7-4"><a href="#cb7-4"></a><span class="kw">def</span> extract_features(<span class="va">self</span>):</span>
<span id="cb7-5"><a href="#cb7-5"></a>    df <span class="op">=</span> pd.read_csv(<span class="va">self</span>.df_path)</span>
<span id="cb7-6"><a href="#cb7-6"></a>    df <span class="op">=</span> df.drop_duplicates(subset<span class="op">=</span>[<span class="st">'tw_texto'</span>], keep<span class="op">=</span><span class="st">'first'</span>)</span>
<span id="cb7-7"><a href="#cb7-7"></a></span>
<span id="cb7-8"><a href="#cb7-8"></a>    <span class="cf">try</span>:</span>
<span id="cb7-9"><a href="#cb7-9"></a>        df_results <span class="op">=</span> pd.read_csv(<span class="va">self</span>.results_df_path)</span>
<span id="cb7-10"><a href="#cb7-10"></a>        df_results <span class="op">=</span> df_results.drop_duplicates(subset<span class="op">=</span>[<span class="st">'tw_texto'</span>], keep<span class="op">=</span><span class="st">'first'</span>)</span>
<span id="cb7-11"><a href="#cb7-11"></a>    <span class="cf">except</span> <span class="pp">FileNotFoundError</span>:</span>
<span id="cb7-12"><a href="#cb7-12"></a>        df_results <span class="op">=</span> pd.DataFrame()</span>
<span id="cb7-13"><a href="#cb7-13"></a></span>
<span id="cb7-14"><a href="#cb7-14"></a>    df_to_process <span class="op">=</span> df[<span class="op">~</span>df[<span class="st">'tw_texto'</span>].isin(df_results[<span class="st">'tw_texto'</span>])]</span>
<span id="cb7-15"><a href="#cb7-15"></a>    df_to_process <span class="op">=</span> df_to_process.dropna()</span>
<span id="cb7-16"><a href="#cb7-16"></a></span>
<span id="cb7-17"><a href="#cb7-17"></a>    <span class="cf">for</span> index, row <span class="kw">in</span> df_to_process.iterrows():</span>
<span id="cb7-18"><a href="#cb7-18"></a>        tweet <span class="op">=</span> row[<span class="st">'tw_texto'</span>]</span>
<span id="cb7-19"><a href="#cb7-19"></a>        response <span class="op">=</span> (</span>
<span id="cb7-20"><a href="#cb7-20"></a>            OpenAIRequest(tweet)</span>
<span id="cb7-21"><a href="#cb7-21"></a>            .preprocess_text()</span>
<span id="cb7-22"><a href="#cb7-22"></a>            .extract_features(prefix<span class="op">=</span><span class="st">'tw_'</span>)</span>
<span id="cb7-23"><a href="#cb7-23"></a>        )</span>
<span id="cb7-24"><a href="#cb7-24"></a>        df_result <span class="op">=</span> pd.DataFrame([response], index<span class="op">=</span>[index])</span>
<span id="cb7-25"><a href="#cb7-25"></a>        df_results <span class="op">=</span> pd.concat([df_results, df_result])</span>
<span id="cb7-26"><a href="#cb7-26"></a>        df_results.to_csv(<span class="va">self</span>.results_df_path, index<span class="op">=</span><span class="va">False</span>)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>A continuación, se procesa cada <em>tweet</em>. Para cada uno, se realiza una solicitud a la API de <em>OpenAI</em> para realizar el procedimiento de <em>feature extraction</em> utilizando al modelo <code>gpt-3.5-turbo</code>. Las características extraídas se añaden al <em>DataFrame</em> de resultados junto con el <em>tweet</em> original y un <em>tag</em> para identificar a qué candidato se refiere cada publicación.</p>
<p>Finalmente, después de procesar todos los <em>tweets</em>, el <em>DataFrame</em> de resultados se guarda en el archivo CSV de salida. Esto se hace después de procesar cada <em>tweet</em> para evitar la pérdida de información en caso de que se produzca un error durante el procedimiento.</p>
</section>
</section>
<section id="análisis-de-la-opinión-pública" class="level2 page-columns page-full" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="análisis-de-la-opinión-pública"><span class="header-section-number">4</span> Análisis de la opinión pública</h2>
<p><em>Cool</em>. Todos los procedimientos anteriores nos llevan a esta situación en la que tenemos un conjunto de datos listo para ser analizado. Como mencioné en algún punto de esta entrada, he publicado <a href="https://github.com/gafnts/2023-election-insights/blob/main/data/tweets_gpt.csv">este <em>dataset</em></a> en un repositorio de <em>GitHub</em>. Síentete libre de descargarlo y hacer tu propio análisis exploratorio de datos; si lo haces, me encantaría conocer qué encuentras. Sin nada más que agregar, el <em>dataset</em> luce así:</p>
<div class="cell page-columns page-full">
<div class="cell-output-display column-screen-inset-right">

<table class="table table-striped table-hover table-condensed" style="font-size: 13px; margin-left: auto; margin-right: auto;">
 <thead>
  <tr>
   <th style="text-align:center;"> fecha </th>
   <th style="text-align:center;"> tweet </th>
   <th style="text-align:center;"> candidato </th>
   <th style="text-align:center;"> retweets </th>
   <th style="text-align:center;"> replies </th>
   <th style="text-align:center;"> likes </th>
   <th style="text-align:center;"> quotes </th>
   <th style="text-align:center;"> impresiones </th>
   <th style="text-align:center;"> valencia </th>
   <th style="text-align:center;"> emocion </th>
   <th style="text-align:center;"> postura </th>
   <th style="text-align:center;"> tono </th>
   <th style="text-align:center;"> amabilidad </th>
   <th style="text-align:center;"> legibilidad </th>
   <th style="text-align:center;"> controversialidad </th>
   <th style="text-align:center;"> informatividad </th>
   <th style="text-align:center;"> sensitivo </th>
  </tr>
 </thead>
<tbody>
  <tr>
   <td style="text-align:center;min-width: 7em; "> 2023-05-15 </td>
   <td style="text-align:center;min-width: 55em; "> Sandra Torres es capaz de todo por mantener el poder. Recibió dinero sucio, se vendió con Alejandro Giammattei para evitar que cancelaran su partido, incluyó a señalados de corrupción y participó de una red de captación de fondos ilícitos. https://t.co/4J2pX1BSx6 </td>
   <td style="text-align:center;min-width: 7em; "> sandra torres </td>
   <td style="text-align:center;"> 0 </td>
   <td style="text-align:center;"> 1 </td>
   <td style="text-align:center;"> 0 </td>
   <td style="text-align:center;"> 0 </td>
   <td style="text-align:center;"> 335 </td>
   <td style="text-align:center;"> negativo </td>
   <td style="text-align:center;"> enojo </td>
   <td style="text-align:center;"> desaprobación </td>
   <td style="text-align:center;"> agresivo </td>
   <td style="text-align:center;"> 0.2 </td>
   <td style="text-align:center;"> 0.8 </td>
   <td style="text-align:center;"> 0.9 </td>
   <td style="text-align:center;"> 0.9 </td>
   <td style="text-align:center;"> FALSE </td>
  </tr>
  <tr>
   <td style="text-align:center;min-width: 7em; "> 2023-05-15 </td>
   <td style="text-align:center;min-width: 55em; "> Sandra Torres anda regalando zapatos a cambio de votos 😡 esto tiene que parar https://t.co/8OltsAmeiq </td>
   <td style="text-align:center;min-width: 7em; "> sandra torres </td>
   <td style="text-align:center;"> 0 </td>
   <td style="text-align:center;"> 0 </td>
   <td style="text-align:center;"> 5 </td>
   <td style="text-align:center;"> 0 </td>
   <td style="text-align:center;"> 420 </td>
   <td style="text-align:center;"> negativo </td>
   <td style="text-align:center;"> enojo </td>
   <td style="text-align:center;"> desaprobación </td>
   <td style="text-align:center;"> agresivo </td>
   <td style="text-align:center;"> 0.2 </td>
   <td style="text-align:center;"> 0.9 </td>
   <td style="text-align:center;"> 0.8 </td>
   <td style="text-align:center;"> 0.8 </td>
   <td style="text-align:center;"> FALSE </td>
  </tr>
  <tr>
   <td style="text-align:center;min-width: 7em; "> 2023-05-15 </td>
   <td style="text-align:center;min-width: 55em; "> Y en donde están los ladrones como Sandra torres. Baldizon. Los arzu. Portillo. Los ríos montt. Los jimmy morales. Los Giammattei y tantos diputados. Que le han robado millones  al pueblo de guatemala. https://t.co/KVngH40GF9 </td>
   <td style="text-align:center;min-width: 7em; "> sandra torres </td>
   <td style="text-align:center;"> 0 </td>
   <td style="text-align:center;"> 0 </td>
   <td style="text-align:center;"> 0 </td>
   <td style="text-align:center;"> 0 </td>
   <td style="text-align:center;"> 234 </td>
   <td style="text-align:center;"> negativo </td>
   <td style="text-align:center;"> enojo </td>
   <td style="text-align:center;"> desaprobación </td>
   <td style="text-align:center;"> agresivo </td>
   <td style="text-align:center;"> 0.2 </td>
   <td style="text-align:center;"> 0.8 </td>
   <td style="text-align:center;"> 0.7 </td>
   <td style="text-align:center;"> 0.9 </td>
   <td style="text-align:center;"> FALSE </td>
  </tr>
  <tr>
   <td style="text-align:center;min-width: 7em; "> 2023-05-15 </td>
   <td style="text-align:center;min-width: 55em; "> #AlertaPopulista 🚨

¿Sandra Torres, sabe cuáles son derechos humanos?

Te presentamos el episodio número 5 de nuestra sección "El Populista de la Semana" con @PalmieriWaelti

#EleccionesGuatemala #Elecciones2023 #Guatemala #EleccionesGT #Populistas #Facts #Noticias https://t.co/MeoijdOE12 </td>
   <td style="text-align:center;min-width: 7em; "> sandra torres </td>
   <td style="text-align:center;"> 6 </td>
   <td style="text-align:center;"> 9 </td>
   <td style="text-align:center;"> 17 </td>
   <td style="text-align:center;"> 1 </td>
   <td style="text-align:center;"> 3186 </td>
   <td style="text-align:center;"> negativo </td>
   <td style="text-align:center;"> enojo </td>
   <td style="text-align:center;"> desaprobación </td>
   <td style="text-align:center;"> agresivo </td>
   <td style="text-align:center;"> 0.2 </td>
   <td style="text-align:center;"> 0.9 </td>
   <td style="text-align:center;"> 0.8 </td>
   <td style="text-align:center;"> 0.8 </td>
   <td style="text-align:center;"> FALSE </td>
  </tr>
  <tr>
   <td style="text-align:center;min-width: 7em; "> 2023-05-15 </td>
   <td style="text-align:center;min-width: 55em; "> La CC dejó en firme la inscripción del binomio presidencial de la UNE conformado por Sandra Torres y Romeo Estuardo Guerra Lemus. 🔽 https://t.co/yG7AEiXV1Y </td>
   <td style="text-align:center;min-width: 7em; "> sandra torres </td>
   <td style="text-align:center;"> 0 </td>
   <td style="text-align:center;"> 0 </td>
   <td style="text-align:center;"> 0 </td>
   <td style="text-align:center;"> 0 </td>
   <td style="text-align:center;"> 129 </td>
   <td style="text-align:center;"> neutro </td>
   <td style="text-align:center;"> otro </td>
   <td style="text-align:center;"> información </td>
   <td style="text-align:center;"> informativo </td>
   <td style="text-align:center;"> 0.8 </td>
   <td style="text-align:center;"> 1.0 </td>
   <td style="text-align:center;"> 0.2 </td>
   <td style="text-align:center;"> 1.0 </td>
   <td style="text-align:center;"> FALSE </td>
  </tr>
  <tr>
   <td style="text-align:center;min-width: 7em; "> 2023-05-15 </td>
   <td style="text-align:center;min-width: 55em; "> 🤔🤣
¿La hija de Sandra Torres hablando de izquierdosos?
¿WTF?!!! https://t.co/Jd4ZaiQ9K3 https://t.co/qk4vZo50aD </td>
   <td style="text-align:center;min-width: 7em; "> sandra torres </td>
   <td style="text-align:center;"> 0 </td>
   <td style="text-align:center;"> 0 </td>
   <td style="text-align:center;"> 2 </td>
   <td style="text-align:center;"> 0 </td>
   <td style="text-align:center;"> 180 </td>
   <td style="text-align:center;"> negativo </td>
   <td style="text-align:center;"> enojo </td>
   <td style="text-align:center;"> desaprobación </td>
   <td style="text-align:center;"> irónico </td>
   <td style="text-align:center;"> 0.2 </td>
   <td style="text-align:center;"> 1.0 </td>
   <td style="text-align:center;"> 0.8 </td>
   <td style="text-align:center;"> 0.6 </td>
   <td style="text-align:center;"> TRUE </td>
  </tr>
</tbody>
</table>

</div>
</div>
<section id="explorando-el-dataset" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="explorando-el-dataset">Explorando el <em>dataset</em></h3>
<p>Como podemos ver, la información extraída considera básicamente las últimas dos semanas del mes de marzo.</p>
<div class="cell">
<details>
<summary>Código</summary>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb8-2"><a href="#cb8-2"></a><span class="fu">library</span>(knitr)</span>
<span id="cb8-3"><a href="#cb8-3"></a><span class="fu">library</span>(kableExtra)</span>
<span id="cb8-4"><a href="#cb8-4"></a></span>
<span id="cb8-5"><a href="#cb8-5"></a>fechas <span class="ot">&lt;-</span> </span>
<span id="cb8-6"><a href="#cb8-6"></a>  df <span class="sc">|&gt;</span> </span>
<span id="cb8-7"><a href="#cb8-7"></a>  <span class="fu">summarise</span>(</span>
<span id="cb8-8"><a href="#cb8-8"></a>    <span class="st">`</span><span class="at">Fecha inicial</span><span class="st">`</span> <span class="ot">=</span> <span class="fu">min</span>(fecha),</span>
<span id="cb8-9"><a href="#cb8-9"></a>    <span class="st">`</span><span class="at">Fecha final</span><span class="st">`</span> <span class="ot">=</span> <span class="fu">max</span>(fecha)</span>
<span id="cb8-10"><a href="#cb8-10"></a>  )</span>
<span id="cb8-11"><a href="#cb8-11"></a></span>
<span id="cb8-12"><a href="#cb8-12"></a><span class="fu">kable</span>(fechas, <span class="at">align =</span> <span class="st">"c"</span>) <span class="sc">|&gt;</span> </span>
<span id="cb8-13"><a href="#cb8-13"></a>  <span class="fu">kable_styling</span>(</span>
<span id="cb8-14"><a href="#cb8-14"></a>    <span class="at">bootstrap_options =</span> <span class="fu">c</span>(<span class="st">"striped"</span>, <span class="st">"hover"</span>, <span class="st">"condensed"</span>), </span>
<span id="cb8-15"><a href="#cb8-15"></a>    <span class="at">full_width =</span> <span class="cn">TRUE</span>,</span>
<span id="cb8-16"><a href="#cb8-16"></a>    <span class="at">font_size =</span> <span class="dv">13</span></span>
<span id="cb8-17"><a href="#cb8-17"></a>  )</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">

<table class="table table-striped table-hover table-condensed" style="font-size: 13px; margin-left: auto; margin-right: auto;">
 <thead>
  <tr>
   <th style="text-align:center;"> Fecha inicial </th>
   <th style="text-align:center;"> Fecha final </th>
  </tr>
 </thead>
<tbody>
  <tr>
   <td style="text-align:center;"> 2023-05-15 </td>
   <td style="text-align:center;"> 2023-05-27 </td>
  </tr>
</tbody>
</table>

</div>
</div>
<p>Durante los procedimientos de extracción se definió la misma cantidad de <em>tweets</em> para cada candidato. Sin embargo, al eliminar <em>tweets</em> duplicados podemos notar que, durante el periodo de tiempo del análisis, las personas en <em>Twitter</em> hablaron casi cuatro veces más de Carlos Pineda (quien, para el momento de la extracción de tweets, aún seguía participando en la contienda electoral) que de Manuel Conde.</p>
<div class="cell">
<details>
<summary>Código</summary>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1"></a>df <span class="sc">|&gt;</span> </span>
<span id="cb9-2"><a href="#cb9-2"></a>  <span class="fu">group_by</span>(candidato) <span class="sc">|&gt;</span> </span>
<span id="cb9-3"><a href="#cb9-3"></a>  <span class="fu">summarise</span>(</span>
<span id="cb9-4"><a href="#cb9-4"></a>    <span class="at">count =</span> <span class="fu">n</span>()</span>
<span id="cb9-5"><a href="#cb9-5"></a>  ) <span class="sc">|&gt;</span> </span>
<span id="cb9-6"><a href="#cb9-6"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="fu">reorder</span>(candidato, <span class="sc">-</span>count), count, <span class="at">fill =</span> candidato)) <span class="sc">+</span></span>
<span id="cb9-7"><a href="#cb9-7"></a>  <span class="fu">geom_col</span>(<span class="at">alpha =</span> <span class="fl">0.6</span>) <span class="sc">+</span></span>
<span id="cb9-8"><a href="#cb9-8"></a>  <span class="fu">labs</span>(</span>
<span id="cb9-9"><a href="#cb9-9"></a>    <span class="at">title =</span> <span class="st">"Cantidad de tweets por candidato"</span></span>
<span id="cb9-10"><a href="#cb9-10"></a>  ) <span class="sc">+</span></span>
<span id="cb9-11"><a href="#cb9-11"></a>  <span class="fu">theme</span>(</span>
<span id="cb9-12"><a href="#cb9-12"></a>    <span class="at">axis.title.x =</span> <span class="fu">element_blank</span>(),</span>
<span id="cb9-13"><a href="#cb9-13"></a>    <span class="at">axis.title.y =</span> <span class="fu">element_blank</span>(),</span>
<span id="cb9-14"><a href="#cb9-14"></a>    <span class="at">legend.title =</span> <span class="fu">element_blank</span>(),</span>
<span id="cb9-15"><a href="#cb9-15"></a>    <span class="at">legend.position =</span> <span class="st">"bottom"</span></span>
<span id="cb9-16"><a href="#cb9-16"></a>  ) <span class="sc">+</span></span>
<span id="cb9-17"><a href="#cb9-17"></a>  <span class="fu">scale_fill_manual</span>(<span class="at">values =</span> palette)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<p><img src="index_files/figure-html/unnamed-chunk-10-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<div class="cell page-columns page-full">

<div class="no-row-height column-margin column-container"><div class="cell-output-display">

<table class="table table-striped table-hover table-condensed" style="font-size: 13px; margin-left: auto; margin-right: auto;">
 <thead>
  <tr>
   <th style="text-align:center;"> Candidato </th>
   <th style="text-align:center;"> Engagement </th>
  </tr>
 </thead>
<tbody>
  <tr>
   <td style="text-align:center;"> carlos pineda </td>
   <td style="text-align:center;"> 0.8963113 </td>
  </tr>
  <tr>
   <td style="text-align:center;"> edmond mulet </td>
   <td style="text-align:center;"> 1.4452980 </td>
  </tr>
  <tr>
   <td style="text-align:center;"> manuel conde </td>
   <td style="text-align:center;"> 1.6900648 </td>
  </tr>
  <tr>
   <td style="text-align:center;"> sandra torres </td>
   <td style="text-align:center;"> 1.4844873 </td>
  </tr>
  <tr>
   <td style="text-align:center;"> zury rios </td>
   <td style="text-align:center;"> 1.9128208 </td>
  </tr>
</tbody>
</table>

</div></div></div>
<p>Pero no solo podemos fijarnos en la cantidad de <em>tweets</em> que mencionan a los candidatos, sería importante también considerar la calidad de estas publicaciones. Para ello, vamos a computar el <em>engagement rate</em> de cada publicación, definido como la suma de interacciones (<em>retweets</em>, <em>replies</em>, <em>likes</em> y <em>quotes</em>) de cada <em>tweet</em>, dividida entre la cantidad de impresiones que la publicación tuvo. Curiosamente, los <em>tweets</em> que mencionan a Carlos Pineda son los que tienen un menor <em>engagement</em>. Mmm, muchos <em>tweets</em> con poco <em>engagement</em>… ¿a ustedes también les suena raro?</p>
<p>La siguiente gráfica muestra la distribución del logaritmo del <em>engagement rate</em> por cada uno de los candidatos. Parece que hablar de Zury Ríos es una buena forma de conseguir atención. Aunque no por mucho. En promedio, solo el 1.9% de las impresiones de los <em>tweets</em> que hablaban de Zury Ríos resultaron en algún tipo de interacción.</p>
<div class="cell">
<details>
<summary>Código</summary>
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1"></a>df <span class="sc">|&gt;</span> </span>
<span id="cb10-2"><a href="#cb10-2"></a>  <span class="fu">mutate</span>(</span>
<span id="cb10-3"><a href="#cb10-3"></a>    <span class="at">engagement =</span> <span class="fu">log</span>(((retweets <span class="sc">+</span> replies <span class="sc">+</span> likes <span class="sc">+</span> quotes) <span class="sc">/</span> impresiones <span class="sc">*</span> <span class="dv">100</span>))</span>
<span id="cb10-4"><a href="#cb10-4"></a>  ) <span class="sc">|&gt;</span> </span>
<span id="cb10-5"><a href="#cb10-5"></a>  <span class="fu">group_by</span>(candidato) <span class="sc">|&gt;</span> </span>
<span id="cb10-6"><a href="#cb10-6"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(engagement, candidato, <span class="at">fill =</span> candidato)) <span class="sc">+</span></span>
<span id="cb10-7"><a href="#cb10-7"></a>  <span class="fu">geom_boxplot</span>(<span class="at">alpha =</span> <span class="fl">0.6</span>, ) <span class="sc">+</span></span>
<span id="cb10-8"><a href="#cb10-8"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Logaritmo de la tasa de engagement por cada candidato"</span>) <span class="sc">+</span></span>
<span id="cb10-9"><a href="#cb10-9"></a>  <span class="fu">theme</span>(</span>
<span id="cb10-10"><a href="#cb10-10"></a>    <span class="at">axis.title.x =</span> <span class="fu">element_blank</span>(),</span>
<span id="cb10-11"><a href="#cb10-11"></a>    <span class="at">axis.title.y =</span> <span class="fu">element_blank</span>(),</span>
<span id="cb10-12"><a href="#cb10-12"></a>    <span class="at">axis.text.y =</span> <span class="fu">element_blank</span>(),</span>
<span id="cb10-13"><a href="#cb10-13"></a>    <span class="at">axis.ticks.y =</span> <span class="fu">element_blank</span>(),</span>
<span id="cb10-14"><a href="#cb10-14"></a>    <span class="at">legend.title =</span> <span class="fu">element_blank</span>(),</span>
<span id="cb10-15"><a href="#cb10-15"></a>    <span class="at">legend.position =</span> <span class="st">"bottom"</span></span>
<span id="cb10-16"><a href="#cb10-16"></a>  ) <span class="sc">+</span></span>
<span id="cb10-17"><a href="#cb10-17"></a>  <span class="fu">scale_fill_manual</span>(<span class="at">values =</span> palette) </span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<p><img src="index_files/figure-html/unnamed-chunk-12-1.png" class="img-fluid" width="672"></p>
</div>
</div>
</section>
<section id="analizando-sentimientos" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="analizando-sentimientos">Analizando sentimientos</h3>
<p>Obviamente, lo más interesante de este análisis es utilizar las variables que fueron generadas por <code>gpt-3.5-turbo</code>. Podemos empezar por preguntarnos si existe alguna relación entre la cantidad de interacciones y la valencia (el sentimiento general) del <em>tweet</em>. Y <em>my oh my</em>, resulta que sí.</p>

<div class="no-row-height column-margin column-container"><div class="">
<p>One-way ANOVA</p>
<div class="cell">
<div class="cell-output-display">

<table class="table table-striped table-hover table-condensed" style="font-size: 13px; margin-left: auto; margin-right: auto;">
 <thead>
  <tr>
   <th style="text-align:center;"> term </th>
   <th style="text-align:center;"> statistic </th>
   <th style="text-align:center;"> p.value </th>
  </tr>
 </thead>
<tbody>
  <tr>
   <td style="text-align:center;"> retweets </td>
   <td style="text-align:center;"> 9.241632 </td>
   <td style="text-align:center;"> 0.0001029 </td>
  </tr>
  <tr>
   <td style="text-align:center;"> replies </td>
   <td style="text-align:center;"> 2.783355 </td>
   <td style="text-align:center;"> 0.0621688 </td>
  </tr>
</tbody>
</table>

</div>
</div>
</div></div><div class="page-columns page-full"><p><em>Tweets</em> con sentimiento negativo tienen más <em>retweets</em> en promedio, mientras que publicaciones con sentimiento positivo tienen, en promedio, más cantidad de respuestas. De hecho, la diferencia entre las medias del logaritmo de la cantidad de <em>retweets</em> segregados por la valencia es estadísticamente significativa, como lo muestra la tabla al margen de esta sección, en la que he realizado un análisis de varianza, tanto para los <em>tweets</em> como para las respuestas.<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a></p><div class="no-row-height column-margin column-container"><li id="fn7"><p><sup>7</sup>&nbsp;Sin embargo, no es posible rechazar la hipótesis nula para el caso de las respuestas. Pero esto a todas luces es debido a que las medias del logaritmo de la cantidad de respuestas para <em>tweets</em> con sentimiento negativo y neutro son prácticamente iguales.</p></li></div></div>
<div class="cell">
<details>
<summary>Código</summary>
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1"></a><span class="fu">library</span>(patchwork)</span>
<span id="cb11-2"><a href="#cb11-2"></a></span>
<span id="cb11-3"><a href="#cb11-3"></a>retweets <span class="ot">&lt;-</span> </span>
<span id="cb11-4"><a href="#cb11-4"></a>  df <span class="sc">|&gt;</span> </span>
<span id="cb11-5"><a href="#cb11-5"></a>  <span class="fu">group_by</span>(candidato) <span class="sc">|&gt;</span> </span>
<span id="cb11-6"><a href="#cb11-6"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(valencia, <span class="fu">log</span>(retweets), <span class="at">fill =</span> valencia)) <span class="sc">+</span></span>
<span id="cb11-7"><a href="#cb11-7"></a>  <span class="fu">geom_boxplot</span>(<span class="at">alpha =</span> <span class="fl">0.6</span>) <span class="sc">+</span></span>
<span id="cb11-8"><a href="#cb11-8"></a>  <span class="fu">labs</span>(<span class="at">y =</span> <span class="st">"Logaritmo de la cantidad de retweets"</span>) <span class="sc">+</span></span>
<span id="cb11-9"><a href="#cb11-9"></a>  <span class="fu">theme</span>(</span>
<span id="cb11-10"><a href="#cb11-10"></a>    <span class="at">axis.title.x =</span> <span class="fu">element_blank</span>(),</span>
<span id="cb11-11"><a href="#cb11-11"></a>    <span class="at">axis.text.y =</span> <span class="fu">element_blank</span>(),</span>
<span id="cb11-12"><a href="#cb11-12"></a>    <span class="at">axis.ticks.y =</span> <span class="fu">element_blank</span>(),</span>
<span id="cb11-13"><a href="#cb11-13"></a>    <span class="at">legend.title =</span> <span class="fu">element_blank</span>(),</span>
<span id="cb11-14"><a href="#cb11-14"></a>    <span class="at">legend.position =</span> <span class="st">"none"</span></span>
<span id="cb11-15"><a href="#cb11-15"></a>  ) <span class="sc">+</span></span>
<span id="cb11-16"><a href="#cb11-16"></a>  <span class="fu">scale_fill_manual</span>(<span class="at">values =</span> palette) </span>
<span id="cb11-17"><a href="#cb11-17"></a></span>
<span id="cb11-18"><a href="#cb11-18"></a>replies <span class="ot">&lt;-</span> </span>
<span id="cb11-19"><a href="#cb11-19"></a>  df <span class="sc">|&gt;</span> </span>
<span id="cb11-20"><a href="#cb11-20"></a>  <span class="fu">group_by</span>(candidato) <span class="sc">|&gt;</span> </span>
<span id="cb11-21"><a href="#cb11-21"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(valencia, <span class="fu">log</span>(replies), <span class="at">fill =</span> valencia)) <span class="sc">+</span></span>
<span id="cb11-22"><a href="#cb11-22"></a>  <span class="fu">geom_boxplot</span>(<span class="at">alpha =</span> <span class="fl">0.6</span>) <span class="sc">+</span></span>
<span id="cb11-23"><a href="#cb11-23"></a>  <span class="fu">labs</span>(<span class="at">y =</span> <span class="st">"Logaritmo de la cantidad de replies"</span>) <span class="sc">+</span></span>
<span id="cb11-24"><a href="#cb11-24"></a>  <span class="fu">theme</span>(</span>
<span id="cb11-25"><a href="#cb11-25"></a>    <span class="at">axis.title.x =</span> <span class="fu">element_blank</span>(),</span>
<span id="cb11-26"><a href="#cb11-26"></a>    <span class="at">axis.text.y =</span> <span class="fu">element_blank</span>(),</span>
<span id="cb11-27"><a href="#cb11-27"></a>    <span class="at">axis.ticks.y =</span> <span class="fu">element_blank</span>(),</span>
<span id="cb11-28"><a href="#cb11-28"></a>    <span class="at">legend.title =</span> <span class="fu">element_blank</span>(),</span>
<span id="cb11-29"><a href="#cb11-29"></a>    <span class="at">legend.position =</span> <span class="st">"none"</span></span>
<span id="cb11-30"><a href="#cb11-30"></a>  ) <span class="sc">+</span></span>
<span id="cb11-31"><a href="#cb11-31"></a>  <span class="fu">scale_fill_manual</span>(<span class="at">values =</span> palette) </span>
<span id="cb11-32"><a href="#cb11-32"></a></span>
<span id="cb11-33"><a href="#cb11-33"></a>retweets <span class="sc">+</span> replies <span class="sc">+</span> </span>
<span id="cb11-34"><a href="#cb11-34"></a>  <span class="fu">plot_annotation</span>(<span class="st">"Relación entre los tipos de interacción y la valencia del mensaje"</span>)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<p><img src="index_files/figure-html/unnamed-chunk-14-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>Otra pregunta importante es cómo se relacionan la controversialidad de los tweets—definida aquí como el potencial de una publicación para generar desacuerdo—y la cantidad de veces que son retuiteados. Podríamos esperar que a mayor controversialidad, mayor sea la probabilidad de obtener más retweets. Esta hipótesis parece confirmarse al observar las regresiones polinomiales locales ajustadas para cada candidato, que demuestran una relación positiva entre la controversialidad y la cantidad de retweets.</p>
<p>En estas regresiones, hemos incluido la puntuación de controversialidad de los tweets, calculada utilizando el modelo GPT durante la extracción de características. En general, los resultados sugieren que los <em>tweets</em> más controvertidos tienden a ser retuiteados con mayor frecuencia para cada uno de los cinco candidatos en nuestro análisis, en promedio.</p>
<div class="cell">
<details>
<summary>Código</summary>
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1"></a>df <span class="sc">|&gt;</span> </span>
<span id="cb12-2"><a href="#cb12-2"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(controversialidad, <span class="fu">log</span>(retweets), <span class="at">color =</span> candidato)) <span class="sc">+</span> </span>
<span id="cb12-3"><a href="#cb12-3"></a>  <span class="fu">geom_jitter</span>(<span class="at">height =</span> <span class="fl">0.3</span>, <span class="at">alpha =</span> <span class="fl">0.6</span>) <span class="sc">+</span> </span>
<span id="cb12-4"><a href="#cb12-4"></a>  <span class="fu">geom_smooth</span>(<span class="at">se =</span> <span class="cn">FALSE</span>, <span class="at">alpha =</span> <span class="fl">0.6</span>) <span class="sc">+</span></span>
<span id="cb12-5"><a href="#cb12-5"></a>  <span class="fu">labs</span>(</span>
<span id="cb12-6"><a href="#cb12-6"></a>    <span class="at">title =</span> <span class="st">"Relación entre la controversialidad y el logaritmo de la cantidad de retweets"</span>,</span>
<span id="cb12-7"><a href="#cb12-7"></a>    <span class="at">x =</span> <span class="st">"Controversialidad del tweet"</span>,</span>
<span id="cb12-8"><a href="#cb12-8"></a>    <span class="at">y =</span> <span class="st">"Logaritmo de la cantidad de retweets"</span></span>
<span id="cb12-9"><a href="#cb12-9"></a>  ) <span class="sc">+</span></span>
<span id="cb12-10"><a href="#cb12-10"></a>  <span class="fu">theme</span>(</span>
<span id="cb12-11"><a href="#cb12-11"></a>    <span class="at">legend.title =</span> <span class="fu">element_blank</span>(),</span>
<span id="cb12-12"><a href="#cb12-12"></a>    <span class="at">legend.position =</span> <span class="st">"bottom"</span></span>
<span id="cb12-13"><a href="#cb12-13"></a>  ) <span class="sc">+</span></span>
<span id="cb12-14"><a href="#cb12-14"></a>  <span class="fu">scale_color_manual</span>(<span class="at">values =</span> palette) </span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<p><img src="index_files/figure-html/.preview-image-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>Para finalizar nuestro análisis, representamos gráficamente la distribución de los <em>tweets</em> divididos en cuatro categorías emocionales: aprobación, desaprobación, esperanza e indiferencia. De forma general, se observa una predominancia de la desaprobación en todos los candidatos analizados, con un promedio del 66 por ciento.</p>
<p>Sandra Torres encabeza esta tendencia, casi un 80 por ciento de los <em>tweets</em> en los que se le menciona reflejan desaprobación. Al mismo tiempo, Torres presenta la segunda menor proporción de <em>tweets</em> con tono de aprobación, siendo solo superada por Carlos Pineda. En cuanto a la indiferencia, Manuel Conde es el candidato que acumula la mayor cantidad de <em>tweets</em> bajo esta postura, en comparación con los demás contendientes.</p>
<div class="cell">
<details>
<summary>Código</summary>
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1"></a>df <span class="sc">|&gt;</span> </span>
<span id="cb13-2"><a href="#cb13-2"></a>  <span class="fu">group_by</span>(candidato, postura) <span class="sc">|&gt;</span> </span>
<span id="cb13-3"><a href="#cb13-3"></a>  <span class="fu">summarise</span>(<span class="at">cantidad =</span> <span class="fu">n</span>()) <span class="sc">|&gt;</span> </span>
<span id="cb13-4"><a href="#cb13-4"></a>  <span class="fu">filter</span>(<span class="fu">str_detect</span>(postura, <span class="st">"aprobación|desaprobación|esperanza|indiferencia"</span>)) <span class="sc">|&gt;</span> </span>
<span id="cb13-5"><a href="#cb13-5"></a>  <span class="fu">mutate</span>(<span class="at">cantidad =</span> cantidad <span class="sc">/</span> <span class="fu">sum</span>(cantidad)) <span class="sc">|&gt;</span> </span>
<span id="cb13-6"><a href="#cb13-6"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="fu">reorder</span>(candidato, cantidad), cantidad, <span class="at">fill =</span> postura)) <span class="sc">+</span></span>
<span id="cb13-7"><a href="#cb13-7"></a>  <span class="fu">geom_col</span>(<span class="at">position =</span> <span class="st">"dodge"</span>, <span class="at">alpha =</span> <span class="fl">0.6</span>) <span class="sc">+</span></span>
<span id="cb13-8"><a href="#cb13-8"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Proporción de tweets por candidato según la postura del usuario"</span>) <span class="sc">+</span></span>
<span id="cb13-9"><a href="#cb13-9"></a>  <span class="fu">theme</span>(</span>
<span id="cb13-10"><a href="#cb13-10"></a>    <span class="at">axis.title.x =</span> <span class="fu">element_blank</span>(),</span>
<span id="cb13-11"><a href="#cb13-11"></a>    <span class="at">axis.title.y =</span> <span class="fu">element_blank</span>(),</span>
<span id="cb13-12"><a href="#cb13-12"></a>    <span class="at">legend.title =</span> <span class="fu">element_blank</span>(),</span>
<span id="cb13-13"><a href="#cb13-13"></a>    <span class="at">legend.position =</span> <span class="st">"bottom"</span></span>
<span id="cb13-14"><a href="#cb13-14"></a>  ) <span class="sc">+</span></span>
<span id="cb13-15"><a href="#cb13-15"></a>  <span class="fu">scale_fill_manual</span>(<span class="at">values =</span> palette) </span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<p><img src="index_files/figure-html/unnamed-chunk-15-1.png" class="img-fluid" width="672"></p>
</div>
</div>
</section>
</section>
<section id="conclusiones" class="level2" data-number="5">
<h2 data-number="5" class="anchored" data-anchor-id="conclusiones"><span class="header-section-number">5</span> Conclusiones</h2>
<p>Durante esta entrada, utilizamos la API de <em>Twitter</em> y la API de <em>OpenAI</em> para decodificar los sentimientos de los usuarios de <em>Twitter</em> en torno a cinco candidatos presidenciales en la contienda electoral de 2023 en Guatemala. Este estudio demostró la eficacia de las tecnologías avanzadas en la comprensión de la dinámica social y política, ilustrando cómo <em>foundation models</em> como <code>gpt-3.5-turbo</code> pueden emplearse para extraer características valiosas y generar <em>insights</em> significativos.</p>
<p>Descargamos <em>tweets</em> que mencionan a los candidatos mediante la <em>Twitter API V2</em> y los utilizamos como nuestro conjunto de datos base. Luego, extraímos características de los <em>tweets</em> utilizando la API de <em>OpenAI</em> y realizamos una exploración inicial de los resultados con R.</p>
<p>Mis reflexiones personales tras realizar estos experimentos se resumen en los siguientes puntos:</p>
<ul>
<li><p>Primero, al interactuar con APIs, la robustez es clave. La capacidad de gestionar eficazmente errores y excepciones es fundamental. Un estudio de <span class="citation" data-cites="papasian2020a">Papasian &amp; Underwood (<a href="#ref-papasian2020a" role="doc-biblioref">2020</a>)</span>, dos ingenieros de aprendizaje automático en <em>Google</em>, destaca que la mayoría de los problemas en sistemas de <em>machine learning</em> no se deben a la implementación de los modelos <em>per se</em>, sino a fallas en los flujos de trabajo de los <em>data pipelines</em>.</p></li>
<li><p>En segundo lugar, mis experiencias con la API de <em>OpenAI</em> han revelado que, si bien GPT es bastante competente en la mayoría de las tareas que he probado, tiene sus limitaciones. Una desventaja notable es el fenómeno popularmente conocido como “alucinaciones”. En <em>edge cases</em> (situaciones inusuales dentro del contenido de los <em>prompts</em> que se envían al modelo), este tiende a inventar nuevas categorías que pueden parecer más adecuadas para el texto, pero que introducen etiquetas que, en teoría, no deberían existir en el conjunto de datos.</p></li>
<li><p>Por último, hay que tener en cuenta que los tiempos de inferencia son relativamente largos. Esto plantea desafíos de escalabilidad al usar este modelo como método de procesamiento, especialmente a medida que el conjunto de datos se expande.</p></li>
</ul>
<p>Este estudio evidencia el emocionante cruce entre las ciencias de la computación y las ciencias sociales, y cómo esta intersección permite generar <em>insights</em> de eventos significativos a través de tecnologías avanzadas. Pese a los desafíos, el resultado es un conjunto de datos valiosos y un análisis significativo de las opiniones de los votantes sobre los candidatos presidenciales.</p>



</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography"><h2 class="anchored quarto-appendix-heading">Referencias</h2><div id="refs" class="references csl-bib-body hanging-indent" data-line-spacing="2" role="doc-bibliography">
<div id="ref-papasian2020a" class="csl-entry" role="doc-biblioentry">
Papasian, D., &amp; Underwood, T. (2020). <em>How <span></span>ML<span></span> Breaks: A Decade of Outages for One Large <span></span>ML<span></span> Pipeline</em>. <a href="https://www.usenix.org/conference/opml20/presentation/papasian">https://www.usenix.org/conference/opml20/presentation/papasian</a>
</div>
</div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copiado");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copiado");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<script src="https://utteranc.es/client.js" repo="gafnts/gafnts.github.io" issue-term="pathname" theme="boxy-light" crossorigin="anonymous" async="">
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">© Gabriel Fuentes (2023)</div>   
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/gafnts">
      <i class="bi bi-github" role="img">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/gafnts">
      <i class="bi bi-twitter" role="img">
</i> 
    </a>
  </li>  
</ul>
    </div>
  </div>
</footer>



<script src="../../site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>