{
  "hash": "82942ac7e6a4b637b1fa09597ff61aa9",
  "result": {
    "markdown": "---\ntitle: \"Revelando los sentimientos guatemaltecos\"\nsubtitle: \"Extracci칩n zero-shot de variables para tweets acerca de las elecciones presidenciales 2023 usando GPT-3.5\"\nimage: feature.png\ndate: today\ncategories: \n  - \"Natural language processing\"\n  - \"Object-oriented programming\"\n  - \"Data engineering\"\nbibliography: references.bib\n---\n\n\n## Decodificando sentimientos\n\nCon las elecciones presidenciales a poco m치s de dos semanas de distancia, la importancia de comprender la voz del p칰blico no puede subestimarse. A trav칠s del uso de t칠cnicas avanzadas, esta entrada busca no solo descubrir patrones en el sentimiento p칰blico, sino tambi칠n demostrar c칩mo la nueva generaci칩n de modelos de lenguaje pueden emplearse para ofrecer perspectivas 칰nicas y valiosas en la din치mica social y pol칤tica de los pa칤ses. Espec칤ficamente, utilizaremos dos poderosos recursos para llevar a cabo este an치lisis: la API de *Twitter* y la API de *OpenAI*.\n\n-   Primero, descargaremos tweets que mencionan a los cinco candidatos que lideraban la encuesta de Prensa Libre publicada a principios de mayo desde la *Twitter API V2* utilizando *Python.*\n-   Estos tweets, entonces, servir치n como nuestro conjunto de datos base para extraer caracter칤sticas utilizando la API de *OpenAI* y su modelo de lenguaje `gpt-3.5-turbo`, empleando una t칠cnica llamada *zero-shot feature extraction*.\n-   Por 칰ltimo, realizaremos una breve exploraci칩n de los resultados utilizando *R*, mi herramienta favorita cuando se trata de procedimientos estad칤sticos y de an치lisis de datos.\n\nA lo largo del blog, explicaremos c칩mo funcionan estas APIs, c칩mo utilizarlas implementando clases en *Python* lo suficientemente robustas como para lidiar con sus errores y excepciones, y c칩mo estos resultados se pueden utilizar para realizar un an치lisis profundo y significativo.\n\nDesde hace varios a침os, la intersecci칩n entre las ciencias de la computaci칩n y las ciencias sociales se ha transformado en uno de mis temas favoritos. Es verdaderamente emocionante darse cuenta de que nos encontramos en un momento 칰nico, en el cual es posible emplear tecnolog칤as de vanguardia para obtener *insights* de eventos significativos. Quiz치s es m치s emocionante a칰n considerar que este tipo de an치lisis habr칤a sido pr치cticamente imposible de llevar a cabo hace solo dos a침os. 쯃ista? 쯃isto?\n\n## Extracci칩n de *tweets* con *Tweepy*\n\nOkay. Cartas sobre la mesa. Implementar estos programas ha conllevado bastante de mi tiempo libre en las 칰ltimas semanas; estoy seguro de que leer todos los detalles sobre estas implementaciones tambi칠n requerir칤a de una cantidad de tiempo considerable, por lo que en esta y la siguiente secci칩n 칰nicamente haremos un repaso por los puntos m치s importantes[^1].\n\n[^1]: Para los lectores m치s interesados he publicado [este repositorio](https://github.com/gafnts/2023-election-insights) en el es posible encontrar todos los m칩dulos utilizados para generar estos resultados. Las clases y sus m칠todos fueron debidamente documentados, pero si칠ntete libre de contactarme si te gustar칤a saber m치s sobre los detalles de estas implementaciones.\n\n### Enviando *requests* hacia la API\n\nLa estructura del repositorio es extremadamente sencilla y el dise침o de las clases se adhiere al *single-responsibility principle*. El directorio `modules` contiene las clases encargadas de comunicarse con las APIs, mientras que los programas `download_tweets.py` y `extract_features.py` se encargan de descargar la informaci칩n en *batches*. En el caso del procedimiento de extracci칩n de *tweets*, el m칩dulo `twitter_request.py` contiene a la clase `TwitterRequest`, responsable de comunicarse con la *Twitter API V2* siguiendo los siguientes pasos:\n\n-   Consultar el *endpoint* `GET_2_tweets_search_recent` de la API utilizando al m칠todo `search_recent_tweets` para extraer los *tweets* que necesitamos.\n-   Procesar la respuesta de la API en formato JSON, convierti칠ndola primero en un *DataFrame*.\n-   Separar a ese *DataFrame* en dos: Uno que contenga informaci칩n de los *tweets* y otro que contenga informaci칩n de los usuarios que realizaron dichas publicaciones.\n-   Preprocesar ambos *DataFrames* para estandarizar los nombres de las columnas y cambiar las columnas que contienen fechas a un formato m치s conveniente.\n\nEn esta clase, el m칠todo m치s importante es `make_request`. Este m칠todo est치 decorado con `@backoff.on_exception` una forma incre칤blemente conveniente de hacer [*exponential backoff*](https://en.wikipedia.org/wiki/Exponential_backoff) en el momento en el que se produzca un error por generar demasiados *requests* o una excepci칩n producto de un *timeout* entre nuestro cliente y el servidor. En cualquiera de estos casos, la funci칩n esperar치 un tiempo exponencialmente creciente antes de volver a intentarlo y 칰nicamente har치 un m치ximo de 5 intentos.\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport tweepy\nimport backoff\nimport requests\nfrom modules import setup_logger\n\n@backoff.on_exception(\n        backoff.expo, \n        (tweepy.errors.TooManyRequests, requests.exceptions.ReadTimeout),\n        max_tries=5\n    )\ndef make_request(self) -> \"TwitterRequest\":\n    self.query = f\"{self.query} -is:retweet -is:reply\"\n    self.logger.info(\"Making request with query: %s\", self.query)\n\n    try:\n        self.tweets = client.search_recent_tweets(\n            query = self.query,\n            start_time = self.start_time,\n            end_time = self.end_time,\n            max_results = self.max_results,\n            tweet_fields = [\n                \"id\", \"author_id\", \"created_at\", \"text\", \n                \"public_metrics\", \"possibly_sensitive\", \"lang\"\n            ],\n            user_fields = [\n                \"id\", \"username\", \"name\", \"location\", \"created_at\", \"description\", \n                \"profile_image_url\", \"verified\", \"public_metrics\"\n            ],\n            expansions = [\n                \"author_id\", \"referenced_tweets.id\"\n            ]\n        )\n        \n        if self.tweets is None or self.tweets.data is None:\n            self.logger.error(\"No tweets returned from request\")\n            return self\n          \n    except Exception as e: \n        self.logger.error(\"Exception occurred\", exc_info=True)\n        raise \n\n    self.logger.info(\"Request completed successfully.\")\n    return self\n```\n:::\n\n\nEl mismo m칠todo define el *query* que se llevar치 a cabo, que en nuestro caso es un *string* con el nombre del candidato mencionado en los *tweets*, pero instruimos a la API para que no devuelva *tweets* que sean *retweets* o respuestas (`f\"{self.query} -is:retweet -is:reply\"`). En la solicitud, se incluyen campos espec칤ficos de los tweets y del usuario que los public칩. Por ejemplo, del *tweet* se solicita el ID, el autor, la fecha de creaci칩n, el texto, las m칠tricas como cantidad de *retweets*, *likes* o respuestas, as칤 como si la publicaci칩n tiene contenido sensible y cu치l es su idioma. Del usuario solicitamos su ID, su *handle*, su nombre, la ubicaci칩n, la fecha de creaci칩n del perfil, la descripci칩n, la imagen de perfil, sus m칠tricas p칰blicas y si su perfil est치 verificado o no[^2].\n\n[^2]: Aunque mis procedimientos extrajeron toda esta informaci칩n para m치s de 5,000 tweets que fueron publicados por m칰ltiples usuarios durante las 칰ltimas dos semanas del mes de mayo, el *Developer Agreement and Policy* de *Twitter* me prohibe publicar la totalidad de la informaci칩n. Sin embargo, he publicado un [dataset reducido](https://github.com/gafnts/2023-election-insights/blob/main/data/tweets_gpt.csv) que contiene 1,420 tweets con sus respectivas m칠tricas p칰blicas y las caracter칤sticas extra칤das utilizando al modelo de lenguaje.\n\nSi la solicitud es exitosa, se obtiene cierta cantidad de *tweets* que son almacenados en el atributo `self.tweets`. Si no se obtiene ninguno, se registra un error en el *log*. Si ocurre alguna otra excepci칩n durante la solicitud, tambi칠n se registra en el *log* y es levantada para que pueda ser manejada por el decorador encargado de hacer exponential *backoff*. Por 칰ltimo, si la solicitud se complet칩 con 칠xito, registramos este hecho en el *log* y retornamos al objeto `self`, para darnos la posibilidad de hacer [*method chaining*](https://stackoverflow.com/questions/41817578/basic-method-chaining).\n\nDe esta forma, utilizar la clase `TwitterRequest` requiere 칰nicamente de inicializarla con los par치metros `query`, `start_time`, `end_time` y `max_results`. *Like so*:\n\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom datetime import datetime\nfrom modules import TwitterRequest\n\ntweets, users = (\n  TwitterRequest(\n      query='zury rios',\n      start_time=datetime(2023, 5, 20, 15, 00),\n      end_time=datetime(2023, 5, 21, 15, 00),\n      max_results=10\n  )\n  .make_request()\n  .tweets_to_dataframe()\n  .users_to_dataframe()\n  .segregate_dataframe()\n  .preprocess_data(\n      tweets_prefix='tw_',\n      users_prefix='us_'\n  )\n)\n```\n:::\n\n\n### Descargando *tweets* en *batches*\n\nTenemos una forma de comunicarnos con la API de *Twitter*, pedirle los datos que nos interesan y preprocesarlos para que est칠n listos para el resto del *pipeline*. Sin embargo, *Twitter* no nos va a hacer la vida f치cil. Su API 칰nicamente permite descargar *tweets* publicados en los 칰ltimos 7 d칤as en batches de 60 *tweets* como m치ximo en un espacio de 15 minutos.[^3]\n\n[^3]: *Overprotective much?*\n\nNi modo. El programa `download_tweets.py` esta dise침ado para lidiar con las restricciones de la API de *Twitter*. El m칠todo `download_tweets` es un componente de la clase `DownloadTweets.` En resumen, este m칠todo descarga *tweets* y usuarios (utilizando el m칠todo `get_batch`, que es un *wrapper* para la clase `TwitterRequest`). Para cada candidato y rango de fechas, se invoca el m칠todo `get_batch` para obtener los *tweets* y usuarios, que se recopilan y se concatenan en dos atributos: `self.tweets` y `self.users`. Finalmente, el m칠todo devuelve estos dos *DataFrames* que contienen todos los *tweets* y usuarios recolectados.\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport pandas as pd\nfrom typing import Tuple\nfrom modules import setup_logger\nfrom modules import TwitterRequest\n\ndef download_tweets(self) -> Tuple[pd.DataFrame, pd.DataFrame]:\n    self.generate_dates()\n    logger.info(f\"Generated {len(self.dates)} date pairs for tweet downloads.\")\n\n    # Collect tweets and users for each candidate.\n    tweets_collector, users_collector = [], []\n    for candidate in self.candidates:\n\n        # Collect tweets and users for each date.\n        dates_tweets_collector, dates_users_collector = [], []\n        for start_date, end_date in self.dates:\n\n            tweets, users = self.get_batch(candidate, start_date, end_date)\n            dates_tweets_collector.append(tweets)\n            dates_users_collector.append(users)\n\n        tweets_collector.append(pd.concat(dates_tweets_collector))\n        users_collector.append(pd.concat(dates_users_collector))\n\n    self.tweets = pd.concat(tweets_collector, axis=0, ignore_index=True)\n    self.users = pd.concat(users_collector, axis=0, ignore_index=True)\n\n    logger.info(\n      f\"Downloaded a total of {len(self.tweets)} tweets and {len(self.users)} users.\"\n    )\n    return self.tweets, self.users\n```\n:::\n\n\n## *Zero-shot feature extraccion* con GPT-3.5\n\nAhora viene una de mis partes favoritas en este proceso. Vamos a usar a GPT-3.5 para generar nuevas *features* basadas en los *tweets* que hemos extra칤do. 쮺칩mo? *Much in the same way we downloaded tweets*, usando una clase llamada `OpenAIRequest` (que se encargar치 de comunicarse con la API) y otra, llamada `FeatureExtraction`, que nos servir치 para procesar las filas del *DataFrame* que contiene las publicaciones de los usuarios de *Twitter*.\n\n### Enviando *requests* hacia la API\n\nEl primer m칠todo relevante en la clase `OpenAIRequest` es `make_request`. De manera similar al m칠todo con el mismo nombre en el procedimiento de extracci칩n de *tweets*, esta funci칩n est치tica est치 decorada con `backoff.on_exception` para poder lidiar con errores en el caso de un *timeout* o por sobrepasar los l칤mites de uso de la API. En el caso del modelo `gpt-3.5-turbo`, podemos realizar una cantidad de 3,500 *requests* por minuto o enviar al *endpoint* un m치ximo 90,000 *tokens* en la misma cantidad de tiempo, lo que pase primero.\n\nComo veremos m치s adelante, el *prompt* con el que instruiremos al modelo tiene, en promedio, 600 *tokens.*[^4] En teor칤a, esto quiere decir que (bas치ndonos en el l칤mite de TPM) podemos enviar 150 *requests* cada 60 segundos. En la pr치ctica, *though*, los tiempos de inferencia de los modelos de lenguaje son bastante altos. En nuestro caso, el tiempo de procesamiento por cada *tweet* fue de aproximadamente 15 segundos, as칤 que extraer caracter칤sticas para 1,420 *tweets* fue un proceso que tom칩 6 horas, *give or take*.\n\n[^4]: *OpenAI* pone a nuestra disposici칩n este [tokenizer](https://platform.openai.com/tokenizer), una herramienta que nos permite hacer un recuento de la cantidad de *tokens* en nuestros *prompts*. En lo personal, me sirve much칤simo para calcular los costos de procesamiento y para asegurarme de que mis *prompts* sean eficientes en t칠rminos de longitud.\n\nLos par치metros que acepta `make_request` son nuestro *prompt*, la especificaci칩n del modelo que queremos utilizar y `temperature`, un par치metro del modelo de lenguaje que puede ser un n칰mero entre 0 y 1. La temperatura controla el grado de aleatoriedad en las respuestas del modelo. Un valor de `temperature` m치s alto (cerca de 1) hace que el modelo genere respuestas m치s diversas y creativas, mientras que un valor m치s bajo (cerca de 0) hace que las respuestas sean m치s determin칤sticas o consistentes.[^5]\n\n[^5]: Los *transformers*, como GPT, son en s칤 mismos arquitecturas de redes neuronales determin칤sticas (es decir, generan la misma salida para una entrada espec칤fica). Sin embargo, se introduce aleatoriedad durante la generaci칩n de texto a trav칠s del muestreo de diferentes secuencias de palabras de acuerdo a las probabilidades de salida del modelo. En general, cuando usamos al modelo como un paso de procesamiento dentro de nuestros *pipelines*, queremos que cada respuesta sea lo m치s consistente posible para reducir las posibilidades de introducir *bugs* en nuestro sistema.\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport openai\nimport backoff\nimport requests\n\n@staticmethod\n@backoff.on_exception(\n    backoff.expo, \n    (openai.error.RateLimitError, requests.exceptions.ReadTimeout),\n    max_tries=5\n)\ndef make_request(prompt: str, model: str = \"gpt-3.5-turbo\", temperature: float = 0) -> str: \n    messages = [{\"role\": \"user\", \"content\": prompt}]\n    response = openai.ChatCompletion.create(\n        model=model,\n        messages=messages,\n        temperature=temperature, \n    )\n    return response.choices[0].message[\"content\"]\n```\n:::\n\n\nEl siguiente m칠todo relevante en la clase `OpenAIRequest` es `extract_features`. En este m칠todo, definimos el *prompt* que ser치 utilizado para instruir al modelo de lenguaje. Este *prompt* es parametrizado a trav칠s de una *f string*, para permitirnos cambiar f치cilmente la entrada seg칰n sea necesario.\n\nUna vez definido el *prompt*, realizamos la consulta a la API de *OpenAI* utilizando el m칠todo `make_request`. Si la respuesta obtenida es nula o inv치lida, registramos un error en el log y retornamos `None`. Adem치s, para robustecer al procedimiento y manejar posibles excepciones durante la solicitud a la API, hemos envuelto este segmento de c칩digo dentro de un bloque *Try Except*. Si todo sale seg칰n lo planeado y obtenemos una respuesta v치lida, la misma es cargada como un diccionario JSON y finalmente retornada por el m칠todo `extract_features`.\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport json\nfrom modules import setup_logger\n\ndef extract_features(self, prefix: str) -> dict:\n    prompt = f\"\"\" (...) \"\"\"\n    \n    try:\n        response = OpenAIRequest.make_request(prompt)\n        if response is None:\n            self.logger.error(\"Received invalid response from OpenAI\")\n            return None\n        response = json.loads(response)\n    except Exception as e:\n        self.logger.error(f\"Exception during API request: {e}\")\n        return None\n\n    return response\n```\n:::\n\n\n### *Prompt engineering*\n\nTengo que confesar algo. Hace unas semanas le칤 en una publicaci칩n de *LinkedIn* una frase que dec칤a algo as칤 como: \"*Calling 'prompt engineering' the action of using ChatGPT today is like calling 'search engineering' to googling something in the early 2000s*\". Y la confesi칩n es que... pienso que es verdad.[^6]\n\n[^6]: Por cierto, ya que estamos confesando cosas. La idea de esta entrada surgi칩 porque hace poco m치s de un mes vi los videos del curso de *deeplearning.ai* llamado [*ChatGPT Prompt Engineering for Developers*](https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/). Es un curso extremadamente corto que tiene informaci칩n 칰til acerca de los casos de uso del modelo desde una perspectiva program치tica. Si est치s leyendo este blog, *chances are you're also gonna like this*.\n\n*Nontheless*, considero que cuando vamos un paso m치s all치 y utilizamos estos modelos desde los *endpoints* que *OpenAI* pone a nuestra disposici칩n, el *hype* que existe hacia el t칠rmino est치 un poco m치s justificado. Principalmente porque, aunque redactamos la instrucci칩n en lenguaje natural, el procedimiento recuerda mucho a definir una serie de pasos en cualquier lenguaje de programaci칩n.\n\nSea como sea que querramos llamarle, para nuestros fines este *prompt* dio buenos resultados:\n\n::: column-page-right\n::: {.callout-tip appearance=\"simple\"}\n\n::: {.cell}\n\n```{.python .cell-code  code-line-numbers=\"false\"}\nprompt = f\"\"\"\nEl siguiente es un tweet que menciona a un candidato presidencial dentro de la contienda electoral 2023 en Guatemala. \n\nPor favor, clasif칤calo de acuerdo a las siguientes categor칤as:\n\nValencia (sentimiento general): [positivo, negativo, neutro, otro]\nEmoci칩n (emoci칩n principal expresada): [felicidad, tristeza, enojo, miedo, sorpresa, disgusto, otro]\nPostura (actitud hacia el tema): [aprobaci칩n, desaprobaci칩n, esperanza, desilusi칩n, indiferencia, confianza, desconfianza, otro]\nTono (forma de expresarse): [agresivo, pasivo, asertivo, esc칠ptico, ir칩nico, humor칤stico, informativo, serio, inspirador, otro]\n\nAdem치s, eval칰alo utilizando una escala continua con rango de 0 a 1 en las siguientes dimensiones:\n\nAmabilidad (nivel de cortes칤a): [0.0 - 1.0]\nLegibilidad (facilidad de lectura): [0.0 - 1.0]\nControversialidad (potencial para generar desacuerdo): [0.0 - 1.0]\nInformatividad (cantidad de informaci칩n relevante y fundamentada): [0.0 - 1.0]\n\nFormatea tu respuesta como un diccionario de Python con las siguientes llaves:\n\n[valencia, emocion, postura, tono, amabilidad, legibilidad, controversialidad, informatividad]\n\nTweet: '''{self.tweet}'''\n\"\"\"\n```\n:::\n\n:::\n:::\n\n### *Zero-shot feature extraction*\n\nEstamos muy cerca de obtener los resultados que buscamos. Hasta el momento, los m칩dulos que hemos implementado nos permiten enviar consultas hacia las APIs de *Twitter* y *OpenAI*, as칤 como descargar lotes de *tweets* que mencionan a los cinco candidatos que encabezaban la encuesta de Prensa Libre, publicada a inicios de mayo. Solo nos falta una forma procesar estos tweets para extraer variables que nos permitan analizarlos a una mayor profundidad. *Enter* `extract_features.py`, un programa en el que la clase `OpenAIRequest` es instanciada dentro de la clase `FeatureExtraction`.\n\nEn el constructor de la clase se inicializan las rutas a dos archivos: `df_path` que es la ruta al archivo CSV de entrada que contiene los *tweets*, y `results_df_path` que es la ruta al archivo CSV de salida donde se almacenar치n las variables extra칤das.\n\nEl principal m칠todo de esta clase es `extract_features`. Este m칠todo primero carga los *tweets* del archivo CSV de entrada y elimina los duplicados. Luego intenta cargar las caracter칤sticas ya extra칤das del archivo CSV de salida. Si este archivo no existe, se inicializa un nuevo *DataFrame* vac칤o. El m칠todo luego determina qu칠 *tweets* a칰n no han sido procesados comparando los *tweets* en los dos *DataFrames* y seleccionando aquellos que solo est치n en el *DataFrame* de entrada.\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport pandas as pd\nfrom modules import OpenAIRequest\n\ndef extract_features(self):\n    df = pd.read_csv(self.df_path)\n    df = df.drop_duplicates(subset=['tw_texto'], keep='first')\n\n    try:\n        df_results = pd.read_csv(self.results_df_path)\n        df_results = df_results.drop_duplicates(subset=['tw_texto'], keep='first')\n    except FileNotFoundError:\n        df_results = pd.DataFrame()\n\n    df_to_process = df[~df['tw_texto'].isin(df_results['tw_texto'])]\n    df_to_process = df_to_process.dropna()\n\n    for index, row in df_to_process.iterrows():\n        tweet = row['tw_texto']\n        response = (\n            OpenAIRequest(tweet)\n            .preprocess_text()\n            .extract_features(prefix='tw_')\n        )\n        df_result = pd.DataFrame([response], index=[index])\n        df_results = pd.concat([df_results, df_result])\n        df_results.to_csv(self.results_df_path, index=False)\n```\n:::\n\n\nA continuaci칩n, se procesa cada *tweet*. Para cada uno, se realiza una solicitud a la API de *OpenAI* para realizar el procedimiento de *feature extraction* utilizando al modelo `gpt-3.5-turbo`. Las caracter칤sticas extra칤das se a침aden al *DataFrame* de resultados junto con el *tweet* original y un *tag* para identificar a qu칠 candidato se refiere cada publicaci칩n.\n\nFinalmente, el *DataFrame* de resultados se guarda en el archivo CSV de salida. Esto se hace despu칠s de procesar cada *tweet* para evitar la p칠rdida de informaci칩n en caso de que se produzca un error durante el procedimiento.\n\n## An치lisis de la opini칩n p칰blica\n\n*Cool*. Todo esto nos lleva a una situaci칩n en la que tenemos un conjunto de datos listo para ser analizado. Como mencion칠 en alg칰n punto de esta entrada, he publicado [este *dataset*](https://github.com/gafnts/2023-election-insights/blob/main/data/tweets_gpt.csv) en un repositorio de *GitHub*. S칤entete libre de descargarlo y hacer tu propio an치lisis exploratorio de datos; si lo haces, me encantar칤a conocer qu칠 encuentras. Sin nada m치s que agregar, el *dataset* luce as칤:\n\n\n::: {.cell .column-screen-inset-right}\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover table-condensed\" style=\"font-size: 13px; margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:center;\"> fecha </th>\n   <th style=\"text-align:center;\"> tweet </th>\n   <th style=\"text-align:center;\"> candidato </th>\n   <th style=\"text-align:center;\"> retweets </th>\n   <th style=\"text-align:center;\"> replies </th>\n   <th style=\"text-align:center;\"> likes </th>\n   <th style=\"text-align:center;\"> quotes </th>\n   <th style=\"text-align:center;\"> impresiones </th>\n   <th style=\"text-align:center;\"> valencia </th>\n   <th style=\"text-align:center;\"> emocion </th>\n   <th style=\"text-align:center;\"> postura </th>\n   <th style=\"text-align:center;\"> tono </th>\n   <th style=\"text-align:center;\"> amabilidad </th>\n   <th style=\"text-align:center;\"> legibilidad </th>\n   <th style=\"text-align:center;\"> controversialidad </th>\n   <th style=\"text-align:center;\"> informatividad </th>\n   <th style=\"text-align:center;\"> sensitivo </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:center;min-width: 7em; \"> 2023-05-15 </td>\n   <td style=\"text-align:center;min-width: 55em; \"> Sandra Torres es capaz de todo por mantener el poder. Recibi칩 dinero sucio, se vendi칩 con Alejandro Giammattei para evitar que cancelaran su partido, incluy칩 a se침alados de corrupci칩n y particip칩 de una red de captaci칩n de fondos il칤citos. https://t.co/4J2pX1BSx6 </td>\n   <td style=\"text-align:center;min-width: 7em; \"> sandra torres </td>\n   <td style=\"text-align:center;\"> 0 </td>\n   <td style=\"text-align:center;\"> 1 </td>\n   <td style=\"text-align:center;\"> 0 </td>\n   <td style=\"text-align:center;\"> 0 </td>\n   <td style=\"text-align:center;\"> 335 </td>\n   <td style=\"text-align:center;\"> negativo </td>\n   <td style=\"text-align:center;\"> enojo </td>\n   <td style=\"text-align:center;\"> desaprobaci칩n </td>\n   <td style=\"text-align:center;\"> agresivo </td>\n   <td style=\"text-align:center;\"> 0.2 </td>\n   <td style=\"text-align:center;\"> 0.8 </td>\n   <td style=\"text-align:center;\"> 0.9 </td>\n   <td style=\"text-align:center;\"> 0.9 </td>\n   <td style=\"text-align:center;\"> FALSE </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;min-width: 7em; \"> 2023-05-15 </td>\n   <td style=\"text-align:center;min-width: 55em; \"> Sandra Torres anda regalando zapatos a cambio de votos 游땨 esto tiene que parar https://t.co/8OltsAmeiq </td>\n   <td style=\"text-align:center;min-width: 7em; \"> sandra torres </td>\n   <td style=\"text-align:center;\"> 0 </td>\n   <td style=\"text-align:center;\"> 0 </td>\n   <td style=\"text-align:center;\"> 5 </td>\n   <td style=\"text-align:center;\"> 0 </td>\n   <td style=\"text-align:center;\"> 420 </td>\n   <td style=\"text-align:center;\"> negativo </td>\n   <td style=\"text-align:center;\"> enojo </td>\n   <td style=\"text-align:center;\"> desaprobaci칩n </td>\n   <td style=\"text-align:center;\"> agresivo </td>\n   <td style=\"text-align:center;\"> 0.2 </td>\n   <td style=\"text-align:center;\"> 0.9 </td>\n   <td style=\"text-align:center;\"> 0.8 </td>\n   <td style=\"text-align:center;\"> 0.8 </td>\n   <td style=\"text-align:center;\"> FALSE </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;min-width: 7em; \"> 2023-05-15 </td>\n   <td style=\"text-align:center;min-width: 55em; \"> Y en donde est치n los ladrones como Sandra torres. Baldizon. Los arzu. Portillo. Los r칤os montt. Los jimmy morales. Los Giammattei y tantos diputados. Que le han robado millones  al pueblo de guatemala. https://t.co/KVngH40GF9 </td>\n   <td style=\"text-align:center;min-width: 7em; \"> sandra torres </td>\n   <td style=\"text-align:center;\"> 0 </td>\n   <td style=\"text-align:center;\"> 0 </td>\n   <td style=\"text-align:center;\"> 0 </td>\n   <td style=\"text-align:center;\"> 0 </td>\n   <td style=\"text-align:center;\"> 234 </td>\n   <td style=\"text-align:center;\"> negativo </td>\n   <td style=\"text-align:center;\"> enojo </td>\n   <td style=\"text-align:center;\"> desaprobaci칩n </td>\n   <td style=\"text-align:center;\"> agresivo </td>\n   <td style=\"text-align:center;\"> 0.2 </td>\n   <td style=\"text-align:center;\"> 0.8 </td>\n   <td style=\"text-align:center;\"> 0.7 </td>\n   <td style=\"text-align:center;\"> 0.9 </td>\n   <td style=\"text-align:center;\"> FALSE </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;min-width: 7em; \"> 2023-05-15 </td>\n   <td style=\"text-align:center;min-width: 55em; \"> #AlertaPopulista 游뚿\n\n쯉andra Torres, sabe cu치les son derechos humanos?\n\nTe presentamos el episodio n칰mero 5 de nuestra secci칩n \"El Populista de la Semana\" con @PalmieriWaelti\n\n#EleccionesGuatemala #Elecciones2023 #Guatemala #EleccionesGT #Populistas #Facts #Noticias https://t.co/MeoijdOE12 </td>\n   <td style=\"text-align:center;min-width: 7em; \"> sandra torres </td>\n   <td style=\"text-align:center;\"> 6 </td>\n   <td style=\"text-align:center;\"> 9 </td>\n   <td style=\"text-align:center;\"> 17 </td>\n   <td style=\"text-align:center;\"> 1 </td>\n   <td style=\"text-align:center;\"> 3186 </td>\n   <td style=\"text-align:center;\"> negativo </td>\n   <td style=\"text-align:center;\"> enojo </td>\n   <td style=\"text-align:center;\"> desaprobaci칩n </td>\n   <td style=\"text-align:center;\"> agresivo </td>\n   <td style=\"text-align:center;\"> 0.2 </td>\n   <td style=\"text-align:center;\"> 0.9 </td>\n   <td style=\"text-align:center;\"> 0.8 </td>\n   <td style=\"text-align:center;\"> 0.8 </td>\n   <td style=\"text-align:center;\"> FALSE </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;min-width: 7em; \"> 2023-05-15 </td>\n   <td style=\"text-align:center;min-width: 55em; \"> La CC dej칩 en firme la inscripci칩n del binomio presidencial de la UNE conformado por Sandra Torres y Romeo Estuardo Guerra Lemus. 游댷 https://t.co/yG7AEiXV1Y </td>\n   <td style=\"text-align:center;min-width: 7em; \"> sandra torres </td>\n   <td style=\"text-align:center;\"> 0 </td>\n   <td style=\"text-align:center;\"> 0 </td>\n   <td style=\"text-align:center;\"> 0 </td>\n   <td style=\"text-align:center;\"> 0 </td>\n   <td style=\"text-align:center;\"> 129 </td>\n   <td style=\"text-align:center;\"> neutro </td>\n   <td style=\"text-align:center;\"> otro </td>\n   <td style=\"text-align:center;\"> informaci칩n </td>\n   <td style=\"text-align:center;\"> informativo </td>\n   <td style=\"text-align:center;\"> 0.8 </td>\n   <td style=\"text-align:center;\"> 1.0 </td>\n   <td style=\"text-align:center;\"> 0.2 </td>\n   <td style=\"text-align:center;\"> 1.0 </td>\n   <td style=\"text-align:center;\"> FALSE </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;min-width: 7em; \"> 2023-05-15 </td>\n   <td style=\"text-align:center;min-width: 55em; \"> 游뱂游뱎\n쯃a hija de Sandra Torres hablando de izquierdosos?\n쯍TF?!!! https://t.co/Jd4ZaiQ9K3 https://t.co/qk4vZo50aD </td>\n   <td style=\"text-align:center;min-width: 7em; \"> sandra torres </td>\n   <td style=\"text-align:center;\"> 0 </td>\n   <td style=\"text-align:center;\"> 0 </td>\n   <td style=\"text-align:center;\"> 2 </td>\n   <td style=\"text-align:center;\"> 0 </td>\n   <td style=\"text-align:center;\"> 180 </td>\n   <td style=\"text-align:center;\"> negativo </td>\n   <td style=\"text-align:center;\"> enojo </td>\n   <td style=\"text-align:center;\"> desaprobaci칩n </td>\n   <td style=\"text-align:center;\"> ir칩nico </td>\n   <td style=\"text-align:center;\"> 0.2 </td>\n   <td style=\"text-align:center;\"> 1.0 </td>\n   <td style=\"text-align:center;\"> 0.8 </td>\n   <td style=\"text-align:center;\"> 0.6 </td>\n   <td style=\"text-align:center;\"> TRUE </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n### Explorando el *dataset*\n\nComo podemos ver, la informaci칩n extra칤da considera b치sicamente las 칰ltimas dos semanas del mes de marzo.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nlibrary(tidyverse)\nlibrary(knitr)\nlibrary(kableExtra)\n\nfechas <- \n  df |> \n  summarise(\n    `Fecha inicial` = min(fecha),\n    `Fecha final` = max(fecha)\n  )\n\nkable(fechas, align = \"c\") |> \n  kable_styling(\n    bootstrap_options = c(\"striped\", \"hover\", \"condensed\"), \n    full_width = TRUE,\n    font_size = 13\n  )\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover table-condensed\" style=\"font-size: 13px; margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:center;\"> Fecha inicial </th>\n   <th style=\"text-align:center;\"> Fecha final </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:center;\"> 2023-05-15 </td>\n   <td style=\"text-align:center;\"> 2023-05-27 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\nDurante los procedimientos de extracci칩n se defini칩 la misma cantidad de *tweets* para cada candidato. Sin embargo, al eliminar *tweets* duplicados podemos notar que, durante el periodo de tiempo del an치lisis, las personas en *Twitter* hablaron casi cuatro veces m치s de Carlos Pineda (quien, para el momento de la extracci칩n de tweets, a칰n segu칤a participando en la contienda electoral) que de Manuel Conde.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\ndf |> \n  group_by(candidato) |> \n  summarise(\n    count = n()\n  ) |> \n  ggplot(aes(reorder(candidato, -count), count, fill = candidato)) +\n  geom_col(alpha = 0.6) +\n  labs(\n    title = \"Cantidad de tweets por candidato\"\n  ) +\n  theme(\n    axis.title.x = element_blank(),\n    axis.title.y = element_blank(),\n    legend.title = element_blank(),\n    legend.position = \"bottom\"\n  ) +\n  scale_fill_manual(values = palette)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n::: {.cell .column-margin}\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover table-condensed\" style=\"font-size: 13px; margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:center;\"> Candidato </th>\n   <th style=\"text-align:center;\"> Engagement </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:center;\"> carlos pineda </td>\n   <td style=\"text-align:center;\"> 0.8963113 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> edmond mulet </td>\n   <td style=\"text-align:center;\"> 1.4452980 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> manuel conde </td>\n   <td style=\"text-align:center;\"> 1.6900648 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> sandra torres </td>\n   <td style=\"text-align:center;\"> 1.4844873 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> zury rios </td>\n   <td style=\"text-align:center;\"> 1.9128208 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\nPero no solo podemos fijarnos en la cantidad de *tweets* que mencionan a los candidatos, ser칤a importante tambi칠n considerar la calidad de estas publicaciones. Para ello, vamos a computar el *engagement rate* de cada publicaci칩n, definido como la suma de interacciones (*retweets*, *replies*, *likes* y *quotes*) de cada *tweet*, dividida entre la cantidad de impresiones que la publicaci칩n tuvo. Curiosamente, los *tweets* que mencionan a Carlos Pineda son los que tienen un menor *engagement*. Mmm, muchos *tweets* con poco *engagement*... 쯔 ustedes tambi칠n les suena raro?\n\nLa siguiente gr치fica muestra la distribuci칩n del logaritmo del *engagement rate* por cada uno de los candidatos. Parece que hablar de Zury R칤os es una buena forma de conseguir atenci칩n. Aunque no por mucho. En promedio, solo el 1.9% de las impresiones de los *tweets* que hablaban de Zury R칤os resultaron en alg칰n tipo de interacci칩n.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\ndf |> \n  mutate(\n    engagement = log(((retweets + replies + likes + quotes) / impresiones * 100))\n  ) |> \n  group_by(candidato) |> \n  ggplot(aes(engagement, candidato, fill = candidato)) +\n  geom_boxplot(alpha = 0.6, ) +\n  labs(title = \"Logaritmo de la tasa de engagement por cada candidato\") +\n  theme(\n    axis.title.x = element_blank(),\n    axis.title.y = element_blank(),\n    axis.text.y = element_blank(),\n    axis.ticks.y = element_blank(),\n    legend.title = element_blank(),\n    legend.position = \"bottom\"\n  ) +\n  scale_fill_manual(values = palette) \n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n\n### Analizando sentimientos\n\nObviamente, lo m치s interesante de este an치lisis es utilizar las variables que fueron generadas por `gpt-3.5-turbo`. Podemos empezar por preguntarnos si existe alguna relaci칩n entre la cantidad de interacciones y la valencia (el sentimiento general) del *tweet*. Y *my oh my*, resulta que s칤.\n\n::: column-margin\nOne-way ANOVA\n\n\n::: {.cell .column-margin}\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover table-condensed\" style=\"font-size: 13px; margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:center;\"> term </th>\n   <th style=\"text-align:center;\"> statistic </th>\n   <th style=\"text-align:center;\"> p.value </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:center;\"> retweets </td>\n   <td style=\"text-align:center;\"> 9.241632 </td>\n   <td style=\"text-align:center;\"> 0.0001029 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> replies </td>\n   <td style=\"text-align:center;\"> 2.783355 </td>\n   <td style=\"text-align:center;\"> 0.0621688 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n:::\n\n*Tweets* con sentimiento negativo tienen m치s *retweets* en promedio, mientras que publicaciones con sentimiento positivo tienen, en promedio, m치s cantidad de respuestas. De hecho, la diferencia entre las medias del logaritmo de la cantidad de *retweets* segregados por la valencia es estad칤sticamente significativa, como lo muestra la tabla al margen de esta secci칩n, en la que he realizado un an치lisis de varianza, tanto para los *tweets* como para las respuestas.[^7]\n\n[^7]: Sin embargo, no es posible rechazar la hip칩tesis nula para el caso de las respuestas. Pero esto a todas luces es debido a que las medias del logaritmo de la cantidad de respuestas para *tweets* con sentimiento negativo y neutro son pr치cticamente iguales.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nlibrary(patchwork)\n\nretweets <- \n  df |> \n  group_by(candidato) |> \n  ggplot(aes(valencia, log(retweets), fill = valencia)) +\n  geom_boxplot(alpha = 0.6) +\n  labs(y = \"Logaritmo de la cantidad de retweets\") +\n  theme(\n    axis.title.x = element_blank(),\n    axis.text.y = element_blank(),\n    axis.ticks.y = element_blank(),\n    legend.title = element_blank(),\n    legend.position = \"none\"\n  ) +\n  scale_fill_manual(values = palette) \n\nreplies <- \n  df |> \n  group_by(candidato) |> \n  ggplot(aes(valencia, log(replies), fill = valencia)) +\n  geom_boxplot(alpha = 0.6) +\n  labs(y = \"Logaritmo de la cantidad de replies\") +\n  theme(\n    axis.title.x = element_blank(),\n    axis.text.y = element_blank(),\n    axis.ticks.y = element_blank(),\n    legend.title = element_blank(),\n    legend.position = \"none\"\n  ) +\n  scale_fill_manual(values = palette) \n\nretweets + replies + \n  plot_annotation(\"Relaci칩n entre los tipos de interacci칩n y la valencia del mensaje\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n\nOtra pregunta importante es c칩mo se relacionan la controversialidad de los tweets---definida aqu칤 como el potencial de una publicaci칩n para generar desacuerdo---y la cantidad de veces que son retuiteados. Podr칤amos esperar que a mayor controversialidad, mayor sea la probabilidad de obtener m치s retweets. Esta hip칩tesis parece confirmarse al observar las regresiones polinomiales locales ajustadas para cada candidato, que demuestran una relaci칩n positiva entre la controversialidad y la cantidad de retweets.\n\nEn estas regresiones, hemos incluido la puntuaci칩n de controversialidad de los tweets, calculada utilizando el modelo GPT durante la extracci칩n de caracter칤sticas. En general, los resultados sugieren que los *tweets* m치s controvertidos tienden a ser retuiteados con mayor frecuencia para cada uno de los cinco candidatos en nuestro an치lisis, en promedio.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\ndf |> \n  ggplot(aes(controversialidad, log(retweets), color = candidato)) + \n  geom_jitter(height = 0.3, alpha = 0.6) + \n  geom_smooth(se = FALSE, alpha = 0.6) +\n  labs(\n    title = \"Relaci칩n entre la controversialidad y el logaritmo de la cantidad de retweets\",\n    x = \"Controversialidad del tweet\",\n    y = \"Logaritmo de la cantidad de retweets\"\n  ) +\n  theme(\n    legend.title = element_blank(),\n    legend.position = \"bottom\"\n  ) +\n  scale_color_manual(values = palette) \n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/.preview-image-1.png){width=672}\n:::\n:::\n\n\nPara finalizar nuestro an치lisis, representamos gr치ficamente la distribuci칩n de los *tweets* divididos en cuatro categor칤as emocionales: aprobaci칩n, desaprobaci칩n, esperanza e indiferencia. De forma general, se observa una predominancia de la desaprobaci칩n en todos los candidatos analizados, con un promedio del 66 por ciento.\n\nSandra Torres encabeza esta tendencia, casi un 80 por ciento de los *tweets* en los que se le menciona reflejan desaprobaci칩n. Al mismo tiempo, Torres presenta la segunda menor proporci칩n de *tweets* con tono de aprobaci칩n, siendo solo superada por Carlos Pineda. En cuanto a la indiferencia, Manuel Conde es el candidato que acumula la mayor cantidad de *tweets* bajo esta postura, en comparaci칩n con los dem치s contendientes.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\ndf |> \n  group_by(candidato, postura) |> \n  summarise(cantidad = n()) |> \n  filter(str_detect(postura, \"aprobaci칩n|desaprobaci칩n|esperanza|indiferencia\")) |> \n  mutate(cantidad = cantidad / sum(cantidad)) |> \n  ggplot(aes(reorder(candidato, cantidad), cantidad, fill = postura)) +\n  geom_col(position = \"dodge\", alpha = 0.6) +\n  labs(title = \"Proporci칩n de tweets por candidato seg칰n la postura del usuario\") +\n  theme(\n    axis.title.x = element_blank(),\n    axis.title.y = element_blank(),\n    legend.title = element_blank(),\n    legend.position = \"bottom\"\n  ) +\n  scale_fill_manual(values = palette) \n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n:::\n\n\n## Conclusiones\n\nDurante esta entrada, utilizamos la API de *Twitter* y la API de *OpenAI* para decodificar los sentimientos de los usuarios de *Twitter* en torno a cinco candidatos presidenciales en la contienda electoral de 2023 en Guatemala. Este ejercicio demostr칩 la eficacia de tecnolog칤as avanzadas en la comprensi칩n de la din치mica social y pol칤tica, ilustrando c칩mo *foundation models* como `gpt-3.5-turbo` pueden emplearse para extraer caracter칤sticas valiosas que permitan generar *insights* significativos.\n\nMis reflexiones personales tras realizar estos experimentos se resumen en los siguientes puntos:\n\n-   Primero, al interactuar con APIs, la robustez es clave. La capacidad de gestionar eficazmente errores y excepciones es fundamental. Un estudio de @papasian2020b, dos ingenieros de aprendizaje autom치tico en *Google*, destaca que la mayor칤a de los problemas en sistemas de *machine learning* no se deben a la implementaci칩n de los modelos *per se*, sino a fallas en los flujos de trabajo de los *data pipelines*.\n\n-   En segundo lugar, tras utilizar en m칰ltiples ocasiones la API de *OpenAI*, he comprobado que, a pesar de que GPT se ha desempe침ado de manera competente en la mayor칤a de tareas en las que lo he puesto a prueba, el modelo tiene ciertas limitaciones significativas. Una de las desventajas m치s notables es el fen칩meno conocido popularmente como \"alucinaciones\". Este se presenta en situaciones excepcionales, *edge cases*, cuando los *prompts* enviados al modelo contienen contenido poco com칰n. En estas circunstancias, el modelo tiende a inventar nuevas categor칤as que podr칤an parecer m치s adecuadas para el texto, pero que introducen etiquetas que, en principio, no deber칤an existir en el conjunto de datos.\n\n    Este aspecto se vincula con el primer punto: al implementar *pipelines* en sistemas de *machine learning* que utilizan *large language models*, es fundamental dise침ar mecanismos que puedan corregir estos *outputs* inesperados de manera eficaz, garantizando as칤 la robustez del sistema en su totalidad.\n\n-   Por 칰ltimo, encuentro que los tiempos de inferencia de GPT son relativamente largos. Esto plantea desaf칤os de escalabilidad al usar este modelo como m칠todo de procesamiento, especialmente a medida que el conjunto de datos se expande.\n\nEsta entrada evidencia el emocionante cruce entre las ciencias de la computaci칩n y las ciencias sociales, y c칩mo esta intersecci칩n permite generar *insights* de eventos significativos a trav칠s de tecnolog칤as avanzadas. Pese a los desaf칤os, el resultado es un conjunto de datos valiosos y un an치lisis de alto nivel acerca de las opiniones expresadas en el debate p칰blico respecto a los candidatos que compiten por ser el pr칩ximo presidente de Guatemala.\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../../site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"../../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}